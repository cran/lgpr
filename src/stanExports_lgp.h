// Generated by rstantools.  Do not edit by hand.

#ifndef MODELS_HPP
#define MODELS_HPP
#define STAN__SERVICES__COMMAND_HPP
#ifndef USE_STANC3
#define USE_STANC3
#endif
#include <rstan/rstaninc.hpp>
// Code generated by stanc v2.26.1-4-gd72b68b7-dirty
#include <stan/model/model_header.hpp>
namespace model_lgp_namespace {
inline void validate_positive_index(const char* var_name, const char* expr,
                                    int val) {
  if (val < 1) {
    std::stringstream msg;
    msg << "Found dimension size less than one in simplex declaration"
        << "; variable=" << var_name << "; dimension size expression=" << expr
        << "; expression value=" << val;
    std::string msg_str(msg.str());
    throw std::invalid_argument(msg_str.c_str());
  }
}
inline void validate_unit_vector_index(const char* var_name, const char* expr,
                                       int val) {
  if (val <= 1) {
    std::stringstream msg;
    if (val == 1) {
      msg << "Found dimension size one in unit vector declaration."
          << " One-dimensional unit vector is discrete"
          << " but the target distribution must be continuous."
          << " variable=" << var_name << "; dimension size expression=" << expr;
    } else {
      msg << "Found dimension size less than one in unit vector declaration"
          << "; variable=" << var_name << "; dimension size expression=" << expr
          << "; expression value=" << val;
    }
    std::string msg_str(msg.str());
    throw std::invalid_argument(msg_str.c_str());
  }
}
using std::istream;
using std::string;
using std::stringstream;
using std::vector;
using std::pow;
using stan::io::dump;
using stan::math::lgamma;
using stan::model::model_base_crtp;
using stan::model::rvalue;
using stan::model::cons_list;
using stan::model::index_uni;
using stan::model::index_max;
using stan::model::index_min;
using stan::model::index_min_max;
using stan::model::index_multi;
using stan::model::index_omni;
using stan::model::nil_index_list;
using namespace stan::math;
using stan::math::pow; 
stan::math::profile_map profiles__;
static int current_statement__= 0;
static const std::vector<string> locations_array__ = {" (found before start of program)",
                                                      " (in 'lgp', line 413, column 2 to column 43)",
                                                      " (in 'lgp', line 414, column 2 to column 39)",
                                                      " (in 'lgp', line 415, column 2 to column 38)",
                                                      " (in 'lgp', line 416, column 2 to column 69)",
                                                      " (in 'lgp', line 417, column 2 to column 73)",
                                                      " (in 'lgp', line 418, column 2 to column 35)",
                                                      " (in 'lgp', line 423, column 2 to column 41)",
                                                      " (in 'lgp', line 425, column 4 to column 68)",
                                                      " (in 'lgp', line 424, column 23 to line 426, column 3)",
                                                      " (in 'lgp', line 424, column 2 to line 426, column 3)",
                                                      " (in 'lgp', line 433, column 4 to column 71)",
                                                      " (in 'lgp', line 432, column 23 to line 434, column 3)",
                                                      " (in 'lgp', line 432, column 2 to line 434, column 3)",
                                                      " (in 'lgp', line 438, column 4 to column 65)",
                                                      " (in 'lgp', line 437, column 21 to line 439, column 3)",
                                                      " (in 'lgp', line 437, column 2 to line 439, column 3)",
                                                      " (in 'lgp', line 443, column 4 to column 65)",
                                                      " (in 'lgp', line 442, column 20 to line 444, column 3)",
                                                      " (in 'lgp', line 442, column 2 to line 444, column 3)",
                                                      " (in 'lgp', line 448, column 4 to column 70)",
                                                      " (in 'lgp', line 447, column 23 to line 449, column 3)",
                                                      " (in 'lgp', line 447, column 2 to line 449, column 3)",
                                                      " (in 'lgp', line 453, column 4 to column 33)",
                                                      " (in 'lgp', line 454, column 4 to column 40)",
                                                      " (in 'lgp', line 455, column 4 to column 43)",
                                                      " (in 'lgp', line 456, column 11 to column 17)",
                                                      " (in 'lgp', line 456, column 4 to column 61)",
                                                      " (in 'lgp', line 458, column 6 to column 65)",
                                                      " (in 'lgp', line 457, column 22 to line 459, column 5)",
                                                      " (in 'lgp', line 457, column 4 to line 459, column 5)",
                                                      " (in 'lgp', line 452, column 23 to line 460, column 3)",
                                                      " (in 'lgp', line 452, column 2 to line 460, column 3)",
                                                      " (in 'lgp', line 461, column 2 to column 69)",
                                                      " (in 'lgp', line 464, column 11 to column 18)",
                                                      " (in 'lgp', line 464, column 20 to column 27)",
                                                      " (in 'lgp', line 464, column 4 to column 57)",
                                                      " (in 'lgp', line 465, column 10 to column 19)",
                                                      " (in 'lgp', line 465, column 28 to column 35)",
                                                      " (in 'lgp', line 465, column 37 to column 44)",
                                                      " (in 'lgp', line 465, column 4 to line 469, column 6)",
                                                      " (in 'lgp', line 471, column 6 to column 18)",
                                                      " (in 'lgp', line 470, column 25 to line 472, column 5)",
                                                      " (in 'lgp', line 470, column 4 to line 472, column 5)",
                                                      " (in 'lgp', line 473, column 4 to column 40)",
                                                      " (in 'lgp', line 474, column 4 to column 63)",
                                                      " (in 'lgp', line 463, column 34 to line 475, column 3)",
                                                      " (in 'lgp', line 463, column 2 to line 475, column 3)",
                                                      " (in 'lgp', line 322, column 2 to column 35)",
                                                      " (in 'lgp', line 323, column 2 to column 46)",
                                                      " (in 'lgp', line 326, column 2 to column 23)",
                                                      " (in 'lgp', line 327, column 2 to column 28)",
                                                      " (in 'lgp', line 328, column 2 to column 27)",
                                                      " (in 'lgp', line 329, column 2 to column 25)",
                                                      " (in 'lgp', line 330, column 2 to column 23)",
                                                      " (in 'lgp', line 331, column 2 to column 22)",
                                                      " (in 'lgp', line 332, column 2 to column 25)",
                                                      " (in 'lgp', line 333, column 2 to column 25)",
                                                      " (in 'lgp', line 334, column 2 to column 22)",
                                                      " (in 'lgp', line 361, column 8 to column 17)",
                                                      " (in 'lgp', line 361, column 2 to column 46)",
                                                      " (in 'lgp', line 364, column 8 to column 19)",
                                                      " (in 'lgp', line 364, column 28 to column 34)",
                                                      " (in 'lgp', line 364, column 2 to column 46)",
                                                      " (in 'lgp', line 365, column 8 to column 19)",
                                                      " (in 'lgp', line 365, column 28 to column 34)",
                                                      " (in 'lgp', line 365, column 2 to column 44)",
                                                      " (in 'lgp', line 366, column 8 to column 19)",
                                                      " (in 'lgp', line 366, column 28 to column 34)",
                                                      " (in 'lgp', line 366, column 2 to column 44)",
                                                      " (in 'lgp', line 369, column 8 to column 19)",
                                                      " (in 'lgp', line 369, column 2 to column 51)",
                                                      " (in 'lgp', line 370, column 2 to column 13)",
                                                      " (in 'lgp', line 371, column 2 to column 26)",
                                                      " (in 'lgp', line 374, column 8 to column 20)",
                                                      " (in 'lgp', line 374, column 29 to column 36)",
                                                      " (in 'lgp', line 374, column 2 to column 45)",
                                                      " (in 'lgp', line 375, column 8 to column 20)",
                                                      " (in 'lgp', line 375, column 29 to column 36)",
                                                      " (in 'lgp', line 375, column 2 to column 52)",
                                                      " (in 'lgp', line 376, column 8 to column 20)",
                                                      " (in 'lgp', line 376, column 22 to column 29)",
                                                      " (in 'lgp', line 376, column 2 to column 47)",
                                                      " (in 'lgp', line 377, column 8 to column 19)",
                                                      " (in 'lgp', line 377, column 21 to column 28)",
                                                      " (in 'lgp', line 377, column 2 to column 40)",
                                                      " (in 'lgp', line 383, column 8 to column 15)",
                                                      " (in 'lgp', line 383, column 2 to column 57)",
                                                      " (in 'lgp', line 386, column 8 to column 17)",
                                                      " (in 'lgp', line 386, column 2 to column 47)",
                                                      " (in 'lgp', line 387, column 8 to column 15)",
                                                      " (in 'lgp', line 387, column 2 to column 43)",
                                                      " (in 'lgp', line 388, column 8 to column 14)",
                                                      " (in 'lgp', line 388, column 2 to column 42)",
                                                      " (in 'lgp', line 389, column 8 to column 19)",
                                                      " (in 'lgp', line 389, column 2 to column 48)",
                                                      " (in 'lgp', line 390, column 8 to column 17)",
                                                      " (in 'lgp', line 390, column 2 to column 39)",
                                                      " (in 'lgp', line 391, column 8 to column 15)",
                                                      " (in 'lgp', line 391, column 2 to column 35)",
                                                      " (in 'lgp', line 392, column 8 to column 14)",
                                                      " (in 'lgp', line 392, column 2 to column 34)",
                                                      " (in 'lgp', line 393, column 8 to column 19)",
                                                      " (in 'lgp', line 393, column 2 to column 40)",
                                                      " (in 'lgp', line 394, column 8 to column 19)",
                                                      " (in 'lgp', line 394, column 2 to column 40)",
                                                      " (in 'lgp', line 395, column 9 to column 16)",
                                                      " (in 'lgp', line 395, column 2 to column 25)",
                                                      " (in 'lgp', line 396, column 2 to column 39)",
                                                      " (in 'lgp', line 397, column 2 to column 31)",
                                                      " (in 'lgp', line 400, column 9 to column 16)",
                                                      " (in 'lgp', line 400, column 2 to column 48)",
                                                      " (in 'lgp', line 403, column 8 to column 17)",
                                                      " (in 'lgp', line 403, column 26 to column 33)",
                                                      " (in 'lgp', line 403, column 35 to column 42)",
                                                      " (in 'lgp', line 403, column 2 to line 406, column 4)",
                                                      " (in 'lgp', line 409, column 9 to column 16)",
                                                      " (in 'lgp', line 409, column 2 to column 57)",
                                                      " (in 'lgp', line 413, column 8 to column 17)",
                                                      " (in 'lgp', line 414, column 8 to column 15)",
                                                      " (in 'lgp', line 415, column 8 to column 14)",
                                                      " (in 'lgp', line 416, column 8 to column 19)",
                                                      " (in 'lgp', line 416, column 56 to column 62)",
                                                      " (in 'lgp', line 417, column 8 to column 19)",
                                                      " (in 'lgp', line 417, column 56 to column 62)",
                                                      " (in 'lgp', line 418, column 8 to column 9)",
                                                      " (in 'lgp', line 423, column 8 to column 19)",
                                                      " (in 'lgp', line 423, column 28 to column 34)",
                                                      " (in 'lgp', line 21, column 4 to column 30)",
                                                      " (in 'lgp', line 22, column 11 to column 12)",
                                                      " (in 'lgp', line 22, column 4 to column 35)",
                                                      " (in 'lgp', line 24, column 6 to column 19)",
                                                      " (in 'lgp', line 23, column 25 to line 25, column 5)",
                                                      " (in 'lgp', line 23, column 4 to line 25, column 5)",
                                                      " (in 'lgp', line 26, column 4 to column 14)",
                                                      " (in 'lgp', line 20, column 56 to line 27, column 3)",
                                                      " (in 'lgp', line 31, column 4 to column 24)",
                                                      " (in 'lgp', line 32, column 4 to column 24)",
                                                      " (in 'lgp', line 33, column 11 to column 13)",
                                                      " (in 'lgp', line 33, column 15 to column 17)",
                                                      " (in 'lgp', line 33, column 4 to column 32)",
                                                      " (in 'lgp', line 35, column 6 to column 20)",
                                                      " (in 'lgp', line 34, column 23 to line 36, column 5)",
                                                      " (in 'lgp', line 34, column 4 to line 36, column 5)",
                                                      " (in 'lgp', line 37, column 4 to column 18)",
                                                      " (in 'lgp', line 30, column 48 to line 38, column 3)",
                                                      " (in 'lgp', line 42, column 4 to column 38)",
                                                      " (in 'lgp', line 41, column 42 to line 43, column 3)",
                                                      " (in 'lgp', line 47, column 4 to column 31)",
                                                      " (in 'lgp', line 46, column 40 to line 48, column 3)",
                                                      " (in 'lgp', line 52, column 4 to column 28)",
                                                      " (in 'lgp', line 53, column 11 to column 14)",
                                                      " (in 'lgp', line 53, column 4 to column 46)",
                                                      " (in 'lgp', line 54, column 4 to column 24)",
                                                      " (in 'lgp', line 55, column 4 to column 31)",
                                                      " (in 'lgp', line 51, column 59 to line 56, column 3)",
                                                      " (in 'lgp', line 65, column 4 to column 33)",
                                                      " (in 'lgp', line 66, column 11 to column 12)",
                                                      " (in 'lgp', line 66, column 4 to column 61)",
                                                      " (in 'lgp', line 67, column 11 to column 12)",
                                                      " (in 'lgp', line 67, column 4 to column 53)",
                                                      " (in 'lgp', line 68, column 4 to column 41)",
                                                      " (in 'lgp', line 64, column 2 to line 69, column 3)",
                                                      " (in 'lgp', line 73, column 4 to column 23)",
                                                      " (in 'lgp', line 74, column 4 to column 15)",
                                                      " (in 'lgp', line 78, column 6 to column 33)",
                                                      " (in 'lgp', line 79, column 6 to column 20)",
                                                      " (in 'lgp', line 77, column 20 to line 80, column 5)",
                                                      " (in 'lgp', line 77, column 4 to line 80, column 5)",
                                                      " (in 'lgp', line 92, column 6 to column 50)",
                                                      " (in 'lgp', line 91, column 26 to line 93, column 5)",
                                                      " (in 'lgp', line 91, column 10 to line 93, column 5)",
                                                      " (in 'lgp', line 90, column 6 to column 50)",
                                                      " (in 'lgp', line 89, column 26 to line 91, column 5)",
                                                      " (in 'lgp', line 89, column 10 to line 93, column 5)",
                                                      " (in 'lgp', line 88, column 6 to column 46)",
                                                      " (in 'lgp', line 87, column 26 to line 89, column 5)",
                                                      " (in 'lgp', line 87, column 10 to line 93, column 5)",
                                                      " (in 'lgp', line 86, column 6 to column 54)",
                                                      " (in 'lgp', line 85, column 26 to line 87, column 5)",
                                                      " (in 'lgp', line 85, column 10 to line 93, column 5)",
                                                      " (in 'lgp', line 84, column 6 to column 47)",
                                                      " (in 'lgp', line 83, column 20 to line 85, column 5)",
                                                      " (in 'lgp', line 83, column 4 to line 93, column 5)",
                                                      " (in 'lgp', line 95, column 4 to column 22)",
                                                      " (in 'lgp', line 72, column 75 to line 96, column 3)",
                                                      " (in 'lgp', line 100, column 4 to column 22)",
                                                      " (in 'lgp', line 101, column 4 to column 22)",
                                                      " (in 'lgp', line 102, column 11 to column 13)",
                                                      " (in 'lgp', line 102, column 15 to column 17)",
                                                      " (in 'lgp', line 102, column 4 to column 21)",
                                                      " (in 'lgp', line 108, column 10 to column 38)",
                                                      " (in 'lgp', line 107, column 15 to line 109, column 9)",
                                                      " (in 'lgp', line 106, column 10 to column 21)",
                                                      " (in 'lgp', line 105, column 28 to line 107, column 9)",
                                                      " (in 'lgp', line 105, column 8 to line 109, column 9)",
                                                      " (in 'lgp', line 104, column 22 to line 110, column 7)",
                                                      " (in 'lgp', line 104, column 6 to line 110, column 7)",
                                                      " (in 'lgp', line 103, column 20 to line 111, column 5)",
                                                      " (in 'lgp', line 103, column 4 to line 111, column 5)",
                                                      " (in 'lgp', line 112, column 4 to column 14)",
                                                      " (in 'lgp', line 99, column 89 to line 113, column 3)",
                                                      " (in 'lgp', line 117, column 4 to column 22)",
                                                      " (in 'lgp', line 118, column 4 to column 22)",
                                                      " (in 'lgp', line 119, column 11 to column 13)",
                                                      " (in 'lgp', line 119, column 14 to column 16)",
                                                      " (in 'lgp', line 119, column 4 to column 20)",
                                                      " (in 'lgp', line 122, column 8 to column 34)",
                                                      " (in 'lgp', line 121, column 22 to line 123, column 7)",
                                                      " (in 'lgp', line 121, column 6 to line 123, column 7)",
                                                      " (in 'lgp', line 120, column 20 to line 124, column 5)",
                                                      " (in 'lgp', line 120, column 4 to line 124, column 5)",
                                                      " (in 'lgp', line 125, column 4 to column 14)",
                                                      " (in 'lgp', line 116, column 67 to line 126, column 3)",
                                                      " (in 'lgp', line 130, column 4 to column 22)",
                                                      " (in 'lgp', line 131, column 4 to column 22)",
                                                      " (in 'lgp', line 132, column 11 to column 13)",
                                                      " (in 'lgp', line 132, column 14 to column 16)",
                                                      " (in 'lgp', line 132, column 4 to column 20)",
                                                      " (in 'lgp', line 135, column 8 to column 45)",
                                                      " (in 'lgp', line 134, column 22 to line 136, column 7)",
                                                      " (in 'lgp', line 134, column 6 to line 136, column 7)",
                                                      " (in 'lgp', line 133, column 20 to line 137, column 5)",
                                                      " (in 'lgp', line 133, column 4 to line 137, column 5)",
                                                      " (in 'lgp', line 138, column 4 to column 14)",
                                                      " (in 'lgp', line 129, column 67 to line 139, column 3)",
                                                      " (in 'lgp', line 146, column 4 to column 30)",
                                                      " (in 'lgp', line 147, column 4 to column 30)",
                                                      " (in 'lgp', line 148, column 11 to column 13)",
                                                      " (in 'lgp', line 148, column 15 to column 17)",
                                                      " (in 'lgp', line 148, column 4 to column 21)",
                                                      " (in 'lgp', line 155, column 6 to column 44)",
                                                      " (in 'lgp', line 153, column 11 to line 156, column 5)",
                                                      " (in 'lgp', line 152, column 6 to column 34)",
                                                      " (in 'lgp', line 151, column 33 to line 153, column 5)",
                                                      " (in 'lgp', line 151, column 11 to line 156, column 5)",
                                                      " (in 'lgp', line 150, column 6 to column 34)",
                                                      " (in 'lgp', line 149, column 26 to line 151, column 5)",
                                                      " (in 'lgp', line 149, column 4 to line 156, column 5)",
                                                      " (in 'lgp', line 157, column 4 to column 14)",
                                                      " (in 'lgp', line 145, column 2 to line 158, column 3)",
                                                      " (in 'lgp', line 168, column 4 to column 37)",
                                                      " (in 'lgp', line 169, column 10 to column 19)",
                                                      " (in 'lgp', line 169, column 28 to column 30)",
                                                      " (in 'lgp', line 169, column 32 to column 34)",
                                                      " (in 'lgp', line 169, column 4 to column 44)",
                                                      " (in 'lgp', line 171, column 13 to column 15)",
                                                      " (in 'lgp', line 171, column 17 to column 19)",
                                                      " (in 'lgp', line 171, column 6 to column 23)",
                                                      " (in 'lgp', line 172, column 6 to column 40)",
                                                      " (in 'lgp', line 173, column 6 to column 26)",
                                                      " (in 'lgp', line 174, column 6 to column 26)",
                                                      " (in 'lgp', line 175, column 6 to column 28)",
                                                      " (in 'lgp', line 176, column 6 to column 29)",
                                                      " (in 'lgp', line 182, column 8 to column 34)",
                                                      " (in 'lgp', line 181, column 13 to line 183, column 7)",
                                                      " (in 'lgp', line 180, column 8 to column 74)",
                                                      " (in 'lgp', line 179, column 25 to line 181, column 7)",
                                                      " (in 'lgp', line 179, column 6 to line 183, column 7)",
                                                      " (in 'lgp', line 187, column 8 to column 36)",
                                                      " (in 'lgp', line 188, column 8 to column 71)",
                                                      " (in 'lgp', line 186, column 36 to line 189, column 7)",
                                                      " (in 'lgp', line 186, column 6 to line 189, column 7)",
                                                      " (in 'lgp', line 190, column 6 to column 21)",
                                                      " (in 'lgp', line 170, column 27 to line 191, column 5)",
                                                      " (in 'lgp', line 170, column 4 to line 191, column 5)",
                                                      " (in 'lgp', line 192, column 4 to column 20)",
                                                      " (in 'lgp', line 167, column 2 to line 193, column 3)",
                                                      " (in 'lgp', line 197, column 4 to column 74)",
                                                      " (in 'lgp', line 196, column 68 to line 198, column 3)",
                                                      " (in 'lgp', line 204, column 4 to column 38)",
                                                      " (in 'lgp', line 205, column 4 to column 40)",
                                                      " (in 'lgp', line 206, column 4 to line 209, column 6)",
                                                      " (in 'lgp', line 203, column 2 to line 210, column 3)",
                                                      " (in 'lgp', line 214, column 4 to line 217, column 6)",
                                                      " (in 'lgp', line 213, column 89 to line 218, column 3)",
                                                      " (in 'lgp', line 243, column 4 to column 20)",
                                                      " (in 'lgp', line 244, column 4 to column 20)",
                                                      " (in 'lgp', line 245, column 4 to column 22)",
                                                      " (in 'lgp', line 246, column 4 to column 37)",
                                                      " (in 'lgp', line 247, column 10 to column 19)",
                                                      " (in 'lgp', line 247, column 28 to column 30)",
                                                      " (in 'lgp', line 247, column 32 to column 34)",
                                                      " (in 'lgp', line 247, column 4 to column 39)",
                                                      " (in 'lgp', line 253, column 13 to column 15)",
                                                      " (in 'lgp', line 253, column 17 to column 19)",
                                                      " (in 'lgp', line 253, column 6 to column 36)",
                                                      " (in 'lgp', line 254, column 13 to column 15)",
                                                      " (in 'lgp', line 254, column 6 to column 20)",
                                                      " (in 'lgp', line 255, column 13 to column 15)",
                                                      " (in 'lgp', line 255, column 6 to column 20)",
                                                      " (in 'lgp', line 258, column 6 to column 40)",
                                                      " (in 'lgp', line 259, column 6 to column 26)",
                                                      " (in 'lgp', line 260, column 6 to column 29)",
                                                      " (in 'lgp', line 261, column 6 to column 29)",
                                                      " (in 'lgp', line 262, column 6 to column 30)",
                                                      " (in 'lgp', line 263, column 6 to column 34)",
                                                      " (in 'lgp', line 264, column 6 to column 29)",
                                                      " (in 'lgp', line 272, column 10 to column 28)",
                                                      " (in 'lgp', line 273, column 10 to column 28)",
                                                      " (in 'lgp', line 271, column 13 to line 274, column 9)",
                                                      " (in 'lgp', line 269, column 10 to column 35)",
                                                      " (in 'lgp', line 270, column 10 to column 35)",
                                                      " (in 'lgp', line 268, column 21 to line 271, column 9)",
                                                      " (in 'lgp', line 268, column 8 to line 274, column 9)",
                                                      " (in 'lgp', line 267, column 20 to line 275, column 7)",
                                                      " (in 'lgp', line 267, column 6 to line 275, column 7)",
                                                      " (in 'lgp', line 279, column 8 to column 15)",
                                                      " (in 'lgp', line 280, column 8 to column 21)",
                                                      " (in 'lgp', line 284, column 10 to column 72)",
                                                      " (in 'lgp', line 285, column 10 to column 72)",
                                                      " (in 'lgp', line 283, column 20 to line 286, column 9)",
                                                      " (in 'lgp', line 283, column 8 to line 286, column 9)",
                                                      " (in 'lgp', line 289, column 8 to column 25)",
                                                      " (in 'lgp', line 291, column 10 to column 61)",
                                                      " (in 'lgp', line 290, column 25 to line 292, column 9)",
                                                      " (in 'lgp', line 290, column 8 to line 292, column 9)",
                                                      " (in 'lgp', line 295, column 8 to column 36)",
                                                      " (in 'lgp', line 296, column 8 to column 36)",
                                                      " (in 'lgp', line 278, column 19 to line 297, column 7)",
                                                      " (in 'lgp', line 278, column 6 to line 297, column 7)",
                                                      " (in 'lgp', line 300, column 6 to column 21)",
                                                      " (in 'lgp', line 305, column 8 to column 41)",
                                                      " (in 'lgp', line 304, column 13 to line 306, column 7)",
                                                      " (in 'lgp', line 302, column 8 to column 21)",
                                                      " (in 'lgp', line 303, column 8 to column 72)",
                                                      " (in 'lgp', line 301, column 20 to line 304, column 7)",
                                                      " (in 'lgp', line 301, column 6 to line 306, column 7)",
                                                      " (in 'lgp', line 310, column 8 to column 69)",
                                                      " (in 'lgp', line 309, column 18 to line 311, column 7)",
                                                      " (in 'lgp', line 309, column 6 to line 311, column 7)",
                                                      " (in 'lgp', line 313, column 6 to column 16)",
                                                      " (in 'lgp', line 250, column 25 to line 314, column 5)",
                                                      " (in 'lgp', line 250, column 4 to line 314, column 5)",
                                                      " (in 'lgp', line 316, column 4 to column 15)",
                                                      " (in 'lgp', line 242, column 2 to line 317, column 3)"};
template <typename T0__>
Eigen::Matrix<stan::promote_args_t<T0__>, -1, 1>
STAN_vectorsum(const std::vector<Eigen::Matrix<T0__, -1, 1>>& vecs,
               const int& L, std::ostream* pstream__) {
  using local_scalar_t__ = stan::promote_args_t<T0__>;
  const static bool propto__ = true;
  (void) propto__;
  local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
  (void) DUMMY_VAR__;  // suppress unused var warning
  
  try {
    int num_vecs;
    num_vecs = std::numeric_limits<int>::min();
    
    current_statement__ = 128;
    num_vecs = stan::math::size(vecs);
    current_statement__ = 129;
    validate_non_negative_index("s", "L", L);
    Eigen::Matrix<local_scalar_t__, -1, 1> s;
    s = Eigen::Matrix<local_scalar_t__, -1, 1>(L);
    stan::math::fill(s, DUMMY_VAR__);
    
    current_statement__ = 130;
    assign(s, nil_index_list(), rep_vector(0, L), "assigning variable s");
    current_statement__ = 133;
    for (int j = 1; j <= num_vecs; ++j) {
      current_statement__ = 131;
      assign(s, nil_index_list(),
        add(stan::model::deep_copy(s), vecs[(j - 1)]), "assigning variable s");
    }
    current_statement__ = 134;
    return s;
  } catch (const std::exception& e) {
    stan::lang::rethrow_located(e, locations_array__[current_statement__]);
      // Next line prevents compiler griping about no return
      throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***"); 
  }
  
}
struct STAN_vectorsum_functor__ {
template <typename T0__>
Eigen::Matrix<stan::promote_args_t<T0__>, -1, 1>
operator()(const std::vector<Eigen::Matrix<T0__, -1, 1>>& vecs, const int& L,
           std::ostream* pstream__)  const 
{
return STAN_vectorsum(vecs, L, pstream__);
}
};
template <typename T0__>
Eigen::Matrix<stan::promote_args_t<T0__>, -1, -1>
STAN_matrix_array_sum(const std::vector<Eigen::Matrix<T0__, -1, -1>>& K,
                      std::ostream* pstream__) {
  using local_scalar_t__ = stan::promote_args_t<T0__>;
  const static bool propto__ = true;
  (void) propto__;
  local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
  (void) DUMMY_VAR__;  // suppress unused var warning
  
  try {
    int n1;
    n1 = std::numeric_limits<int>::min();
    
    current_statement__ = 136;
    n1 = rows(K[(1 - 1)]);
    int n2;
    n2 = std::numeric_limits<int>::min();
    
    current_statement__ = 137;
    n2 = cols(K[(1 - 1)]);
    current_statement__ = 138;
    validate_non_negative_index("K_sum", "n1", n1);
    current_statement__ = 139;
    validate_non_negative_index("K_sum", "n2", n2);
    Eigen::Matrix<local_scalar_t__, -1, -1> K_sum;
    K_sum = Eigen::Matrix<local_scalar_t__, -1, -1>(n1, n2);
    stan::math::fill(K_sum, DUMMY_VAR__);
    
    current_statement__ = 140;
    assign(K_sum, nil_index_list(), K[(1 - 1)], "assigning variable K_sum");
    current_statement__ = 143;
    for (int j = 2; j <= stan::math::size(K); ++j) {
      current_statement__ = 141;
      assign(K_sum, nil_index_list(),
        add(stan::model::deep_copy(K_sum), K[(j - 1)]),
        "assigning variable K_sum");}
    current_statement__ = 144;
    return K_sum;
  } catch (const std::exception& e) {
    stan::lang::rethrow_located(e, locations_array__[current_statement__]);
      // Next line prevents compiler griping about no return
      throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***"); 
  }
  
}
struct STAN_matrix_array_sum_functor__ {
template <typename T0__>
Eigen::Matrix<stan::promote_args_t<T0__>, -1, -1>
operator()(const std::vector<Eigen::Matrix<T0__, -1, -1>>& K,
           std::ostream* pstream__)  const 
{
return STAN_matrix_array_sum(K, pstream__);
}
};
template <typename T0__, typename T1__>
Eigen::Matrix<stan::promote_args_t<stan::value_type_t<T0__>,
T1__>, -1, 1>
STAN_warp_input(const T0__& x_arg__, const T1__& a, std::ostream* pstream__) {
  using local_scalar_t__ = stan::promote_args_t<stan::value_type_t<T0__>,
          T1__>;
  const auto& x = to_ref(x_arg__);
  const static bool propto__ = true;
  (void) propto__;
  local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
  (void) DUMMY_VAR__;  // suppress unused var warning
  
  try {
    current_statement__ = 146;
    return add(-1,
             multiply(2, inv(add(1, stan::math::exp(multiply(-a, x))))));
  } catch (const std::exception& e) {
    stan::lang::rethrow_located(e, locations_array__[current_statement__]);
      // Next line prevents compiler griping about no return
      throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***"); 
  }
  
}
struct STAN_warp_input_functor__ {
template <typename T0__, typename T1__>
Eigen::Matrix<stan::promote_args_t<stan::value_type_t<T0__>,
T1__>, -1, 1>
operator()(const T0__& x, const T1__& a, std::ostream* pstream__)  const 
{
return STAN_warp_input(x, a, pstream__);
}
};
template <typename T0__, typename T1__>
Eigen::Matrix<stan::promote_args_t<stan::value_type_t<T0__>,
T1__>, -1, 1>
STAN_var_mask(const T0__& x_arg__, const T1__& a, std::ostream* pstream__) {
  using local_scalar_t__ = stan::promote_args_t<stan::value_type_t<T0__>,
          T1__>;
  const auto& x = to_ref(x_arg__);
  const static bool propto__ = true;
  (void) propto__;
  local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
  (void) DUMMY_VAR__;  // suppress unused var warning
  
  try {
    current_statement__ = 148;
    return inv(add(1, stan::math::exp(multiply(-a, x))));
  } catch (const std::exception& e) {
    stan::lang::rethrow_located(e, locations_array__[current_statement__]);
      // Next line prevents compiler griping about no return
      throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***"); 
  }
  
}
struct STAN_var_mask_functor__ {
template <typename T0__, typename T1__>
Eigen::Matrix<stan::promote_args_t<stan::value_type_t<T0__>,
T1__>, -1, 1>
operator()(const T0__& x, const T1__& a, std::ostream* pstream__)  const 
{
return STAN_var_mask(x, a, pstream__);
}
};
template <typename T0__>
Eigen::Matrix<stan::promote_args_t<stan::value_type_t<T0__>>, -1, 1>
STAN_expand(const T0__& v_arg__, const std::vector<int>& idx_expand,
            std::ostream* pstream__) {
  using local_scalar_t__ = stan::promote_args_t<stan::value_type_t<T0__>>;
  const auto& v = to_ref(v_arg__);
  const static bool propto__ = true;
  (void) propto__;
  local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
  (void) DUMMY_VAR__;  // suppress unused var warning
  
  try {
    int L;
    L = std::numeric_limits<int>::min();
    
    current_statement__ = 150;
    L = num_elements(v);
    current_statement__ = 151;
    validate_non_negative_index("v_add0", "L + 1", (L + 1));
    Eigen::Matrix<local_scalar_t__, -1, 1> v_add0;
    v_add0 = Eigen::Matrix<local_scalar_t__, -1, 1>((L + 1));
    stan::math::fill(v_add0, DUMMY_VAR__);
    
    current_statement__ = 152;
    assign(v_add0, nil_index_list(), rep_vector(0.0, (L + 1)),
      "assigning variable v_add0");
    current_statement__ = 153;
    assign(v_add0, cons_list(index_min_max(2, (L + 1)), nil_index_list()), v,
      "assigning variable v_add0");
    current_statement__ = 154;
    return rvalue(v_add0,
             cons_list(index_multi(idx_expand), nil_index_list()), "v_add0");
  } catch (const std::exception& e) {
    stan::lang::rethrow_located(e, locations_array__[current_statement__]);
      // Next line prevents compiler griping about no return
      throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***"); 
  }
  
}
struct STAN_expand_functor__ {
template <typename T0__>
Eigen::Matrix<stan::promote_args_t<stan::value_type_t<T0__>>, -1, 1>
operator()(const T0__& v, const std::vector<int>& idx_expand,
           std::ostream* pstream__)  const 
{
return STAN_expand(v, idx_expand, pstream__);
}
};
template <typename T0__, typename T2__, typename T3__>
Eigen::Matrix<stan::promote_args_t<stan::value_type_t<T0__>, stan::value_type_t<T2__>,
stan::value_type_t<T3__>>, -1, 1>
STAN_edit_x_cont(const T0__& x_cont_arg__,
                 const std::vector<int>& idx_expand,
                 const T2__& teff_obs_arg__, const T3__& teff_arg__,
                 std::ostream* pstream__) {
  using local_scalar_t__ = stan::promote_args_t<stan::value_type_t<T0__>,
          stan::value_type_t<T2__>,
          stan::value_type_t<T3__>>;
  const auto& x_cont = to_ref(x_cont_arg__);
  const auto& teff_obs = to_ref(teff_obs_arg__);
  const auto& teff = to_ref(teff_arg__);
  const static bool propto__ = true;
  (void) propto__;
  local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
  (void) DUMMY_VAR__;  // suppress unused var warning
  
  try {
    int n;
    n = std::numeric_limits<int>::min();
    
    current_statement__ = 156;
    n = num_elements(x_cont);
    current_statement__ = 157;
    validate_non_negative_index("x_teff_obs", "n", n);
    Eigen::Matrix<local_scalar_t__, -1, 1> x_teff_obs;
    x_teff_obs = Eigen::Matrix<local_scalar_t__, -1, 1>(n);
    stan::math::fill(x_teff_obs, DUMMY_VAR__);
    
    current_statement__ = 158;
    assign(x_teff_obs, nil_index_list(),
      STAN_expand(teff_obs, idx_expand, pstream__),
      "assigning variable x_teff_obs");
    current_statement__ = 159;
    validate_non_negative_index("x_teff", "n", n);
    Eigen::Matrix<local_scalar_t__, -1, 1> x_teff;
    x_teff = Eigen::Matrix<local_scalar_t__, -1, 1>(n);
    stan::math::fill(x_teff, DUMMY_VAR__);
    
    current_statement__ = 160;
    assign(x_teff, nil_index_list(),
      STAN_expand(teff, idx_expand, pstream__), "assigning variable x_teff");
    current_statement__ = 161;
    return subtract(add(x_cont, x_teff_obs), x_teff);
  } catch (const std::exception& e) {
    stan::lang::rethrow_located(e, locations_array__[current_statement__]);
      // Next line prevents compiler griping about no return
      throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***"); 
  }
  
}
struct STAN_edit_x_cont_functor__ {
template <typename T0__, typename T2__, typename T3__>
Eigen::Matrix<stan::promote_args_t<stan::value_type_t<T0__>, stan::value_type_t<T2__>,
stan::value_type_t<T3__>>, -1, 1>
operator()(const T0__& x_cont, const std::vector<int>& idx_expand,
           const T2__& teff_obs, const T3__& teff, std::ostream* pstream__)  const 
{
return STAN_edit_x_cont(x_cont, idx_expand, teff_obs, teff, pstream__);
}
};
template <typename T0__>
stan::promote_args_t<T0__>
STAN_log_prior(const T0__& x, const std::vector<int>& types,
               const std::vector<double>& p, std::ostream* pstream__) {
  using local_scalar_t__ = stan::promote_args_t<T0__>;
  const static bool propto__ = true;
  (void) propto__;
  local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
  (void) DUMMY_VAR__;  // suppress unused var warning
  
  try {
    local_scalar_t__ log_prior;
    log_prior = DUMMY_VAR__;
    
    current_statement__ = 163;
    log_prior = 0;
    local_scalar_t__ t;
    t = DUMMY_VAR__;
    
    current_statement__ = 164;
    t = x;
    current_statement__ = 168;
    if (logical_eq(types[(2 - 1)], 1)) {
      current_statement__ = 165;
      log_prior = (log_prior + stan::math::log(stan::math::abs((2 * x))));
      current_statement__ = 166;
      t = square(x);
    } 
    current_statement__ = 183;
    if (logical_eq(types[(1 - 1)], 2)) {
      current_statement__ = 181;
      log_prior = (log_prior + normal_lpdf<false>(t, p[(1 - 1)], p[(2 - 1)]));
    } else {
      current_statement__ = 180;
      if (logical_eq(types[(1 - 1)], 3)) {
        current_statement__ = 178;
        log_prior = (log_prior +
                      student_t_lpdf<false>(t, p[(1 - 1)], 0.0, 1.0));
      } else {
        current_statement__ = 177;
        if (logical_eq(types[(1 - 1)], 4)) {
          current_statement__ = 175;
          log_prior = (log_prior +
                        gamma_lpdf<false>(t, p[(1 - 1)], p[(2 - 1)]));
        } else {
          current_statement__ = 174;
          if (logical_eq(types[(1 - 1)], 5)) {
            current_statement__ = 172;
            log_prior = (log_prior +
                          inv_gamma_lpdf<false>(t, p[(1 - 1)], p[(2 - 1)]));
          } else {
            current_statement__ = 171;
            if (logical_eq(types[(1 - 1)], 6)) {
              current_statement__ = 169;
              log_prior = (log_prior +
                            lognormal_lpdf<false>(t, p[(1 - 1)], p[(2 - 1)]));
            } 
          }
        }
      }
    }
    current_statement__ = 184;
    return log_prior;
  } catch (const std::exception& e) {
    stan::lang::rethrow_located(e, locations_array__[current_statement__]);
      // Next line prevents compiler griping about no return
      throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***"); 
  }
  
}
struct STAN_log_prior_functor__ {
template <typename T0__>
stan::promote_args_t<T0__>
operator()(const T0__& x, const std::vector<int>& types,
           const std::vector<double>& p, std::ostream* pstream__)  const 
{
return STAN_log_prior(x, types, p, pstream__);
}
};
Eigen::Matrix<double, -1, -1>
STAN_kernel_zerosum(const std::vector<int>& x1, const std::vector<int>& x2,
                    const int& num_cat, std::ostream* pstream__) {
  using local_scalar_t__ = double;
  const static bool propto__ = true;
  (void) propto__;
  local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
  (void) DUMMY_VAR__;  // suppress unused var warning
  
  try {
    int n1;
    n1 = std::numeric_limits<int>::min();
    
    current_statement__ = 186;
    n1 = stan::math::size(x1);
    int n2;
    n2 = std::numeric_limits<int>::min();
    
    current_statement__ = 187;
    n2 = stan::math::size(x2);
    current_statement__ = 188;
    validate_non_negative_index("K", "n1", n1);
    current_statement__ = 189;
    validate_non_negative_index("K", "n2", n2);
    Eigen::Matrix<local_scalar_t__, -1, -1> K;
    K = Eigen::Matrix<local_scalar_t__, -1, -1>(n1, n2);
    stan::math::fill(K, DUMMY_VAR__);
    
    current_statement__ = 199;
    for (int i = 1; i <= n1; ++i) {
      current_statement__ = 197;
      for (int j = 1; j <= n2; ++j) {
        current_statement__ = 195;
        if (logical_eq(x1[(i - 1)], x2[(j - 1)])) {
          current_statement__ = 193;
          assign(K,
            cons_list(index_uni(i),
              cons_list(index_uni(j), nil_index_list())), 1,
            "assigning variable K");
        } else {
          current_statement__ = 191;
          assign(K,
            cons_list(index_uni(i),
              cons_list(index_uni(j), nil_index_list())),
            -inv((num_cat - 1)), "assigning variable K");
        }}}
    current_statement__ = 200;
    return K;
  } catch (const std::exception& e) {
    stan::lang::rethrow_located(e, locations_array__[current_statement__]);
      // Next line prevents compiler griping about no return
      throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***"); 
  }
  
}
struct STAN_kernel_zerosum_functor__ {
Eigen::Matrix<double, -1, -1>
operator()(const std::vector<int>& x1, const std::vector<int>& x2,
           const int& num_cat, std::ostream* pstream__)  const 
{
return STAN_kernel_zerosum(x1, x2, num_cat, pstream__);
}
};
Eigen::Matrix<double, -1, -1>
STAN_kernel_cat(const std::vector<int>& x1, const std::vector<int>& x2,
                std::ostream* pstream__) {
  using local_scalar_t__ = double;
  const static bool propto__ = true;
  (void) propto__;
  local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
  (void) DUMMY_VAR__;  // suppress unused var warning
  
  try {
    int n1;
    n1 = std::numeric_limits<int>::min();
    
    current_statement__ = 202;
    n1 = stan::math::size(x1);
    int n2;
    n2 = std::numeric_limits<int>::min();
    
    current_statement__ = 203;
    n2 = stan::math::size(x2);
    current_statement__ = 204;
    validate_non_negative_index("K", "n1", n1);
    current_statement__ = 205;
    validate_non_negative_index("K", "n2", n2);
    Eigen::Matrix<local_scalar_t__, -1, -1> K;
    K = Eigen::Matrix<local_scalar_t__, -1, -1>(n1, n2);
    stan::math::fill(K, DUMMY_VAR__);
    
    current_statement__ = 211;
    for (int i = 1; i <= n1; ++i) {
      current_statement__ = 209;
      for (int j = 1; j <= n2; ++j) {
        current_statement__ = 207;
        assign(K,
          cons_list(index_uni(i), cons_list(index_uni(j), nil_index_list())),
          logical_eq(x1[(i - 1)], x2[(j - 1)]), "assigning variable K");}}
    current_statement__ = 212;
    return K;
  } catch (const std::exception& e) {
    stan::lang::rethrow_located(e, locations_array__[current_statement__]);
      // Next line prevents compiler griping about no return
      throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***"); 
  }
  
}
struct STAN_kernel_cat_functor__ {
Eigen::Matrix<double, -1, -1>
operator()(const std::vector<int>& x1, const std::vector<int>& x2,
           std::ostream* pstream__)  const 
{
return STAN_kernel_cat(x1, x2, pstream__);
}
};
Eigen::Matrix<double, -1, -1>
STAN_kernel_bin(const std::vector<int>& x1, const std::vector<int>& x2,
                std::ostream* pstream__) {
  using local_scalar_t__ = double;
  const static bool propto__ = true;
  (void) propto__;
  local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
  (void) DUMMY_VAR__;  // suppress unused var warning
  
  try {
    int n1;
    n1 = std::numeric_limits<int>::min();
    
    current_statement__ = 214;
    n1 = stan::math::size(x1);
    int n2;
    n2 = std::numeric_limits<int>::min();
    
    current_statement__ = 215;
    n2 = stan::math::size(x2);
    current_statement__ = 216;
    validate_non_negative_index("K", "n1", n1);
    current_statement__ = 217;
    validate_non_negative_index("K", "n2", n2);
    Eigen::Matrix<local_scalar_t__, -1, -1> K;
    K = Eigen::Matrix<local_scalar_t__, -1, -1>(n1, n2);
    stan::math::fill(K, DUMMY_VAR__);
    
    current_statement__ = 223;
    for (int i = 1; i <= n1; ++i) {
      current_statement__ = 221;
      for (int j = 1; j <= n2; ++j) {
        current_statement__ = 219;
        assign(K,
          cons_list(index_uni(i), cons_list(index_uni(j), nil_index_list())),
          (logical_eq(x1[(i - 1)], 0) * logical_eq(x2[(j - 1)], 0)),
          "assigning variable K");}}
    current_statement__ = 224;
    return K;
  } catch (const std::exception& e) {
    stan::lang::rethrow_located(e, locations_array__[current_statement__]);
      // Next line prevents compiler griping about no return
      throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***"); 
  }
  
}
struct STAN_kernel_bin_functor__ {
Eigen::Matrix<double, -1, -1>
operator()(const std::vector<int>& x1, const std::vector<int>& x2,
           std::ostream* pstream__)  const 
{
return STAN_kernel_bin(x1, x2, pstream__);
}
};
Eigen::Matrix<double, -1, -1>
STAN_kernel_const(const std::vector<int>& x1, const std::vector<int>& x2,
                  const int& kernel_type, const int& ncat,
                  std::ostream* pstream__) {
  using local_scalar_t__ = double;
  const static bool propto__ = true;
  (void) propto__;
  local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
  (void) DUMMY_VAR__;  // suppress unused var warning
  
  try {
    int n1;
    n1 = std::numeric_limits<int>::min();
    
    current_statement__ = 226;
    n1 = num_elements(x1);
    int n2;
    n2 = std::numeric_limits<int>::min();
    
    current_statement__ = 227;
    n2 = num_elements(x2);
    current_statement__ = 228;
    validate_non_negative_index("K", "n1", n1);
    current_statement__ = 229;
    validate_non_negative_index("K", "n2", n2);
    Eigen::Matrix<local_scalar_t__, -1, -1> K;
    K = Eigen::Matrix<local_scalar_t__, -1, -1>(n1, n2);
    stan::math::fill(K, DUMMY_VAR__);
    
    current_statement__ = 238;
    if (logical_eq(kernel_type, 1)) {
      current_statement__ = 236;
      assign(K, nil_index_list(), STAN_kernel_cat(x1, x2, pstream__),
        "assigning variable K");
    } else {
      current_statement__ = 235;
      if (logical_eq(kernel_type, 2)) {
        current_statement__ = 233;
        assign(K, nil_index_list(), STAN_kernel_bin(x1, x2, pstream__),
          "assigning variable K");
      } else {
        current_statement__ = 231;
        assign(K, nil_index_list(),
          STAN_kernel_zerosum(x1, x2, ncat, pstream__),
          "assigning variable K");
      }
    }
    current_statement__ = 239;
    return K;
  } catch (const std::exception& e) {
    stan::lang::rethrow_located(e, locations_array__[current_statement__]);
      // Next line prevents compiler griping about no return
      throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***"); 
  }
  
}
struct STAN_kernel_const_functor__ {
Eigen::Matrix<double, -1, -1>
operator()(const std::vector<int>& x1, const std::vector<int>& x2,
           const int& kernel_type, const int& ncat, std::ostream* pstream__)  const 
{
return STAN_kernel_const(x1, x2, kernel_type, ncat, pstream__);
}
};
std::vector<Eigen::Matrix<double, -1, -1>>
STAN_kernel_const_all(const int& n1, const int& n2,
                      const std::vector<std::vector<int>>& x1,
                      const std::vector<std::vector<int>>& x2,
                      const std::vector<std::vector<int>>& x1_mask,
                      const std::vector<std::vector<int>>& x2_mask,
                      const std::vector<int>& num_levels,
                      const std::vector<std::vector<int>>& components,
                      std::ostream* pstream__) {
  using local_scalar_t__ = double;
  const static bool propto__ = true;
  (void) propto__;
  local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
  (void) DUMMY_VAR__;  // suppress unused var warning
  
  try {
    int num_comps;
    num_comps = std::numeric_limits<int>::min();
    
    current_statement__ = 241;
    num_comps = stan::math::size(components);
    current_statement__ = 242;
    validate_non_negative_index("K_const", "num_comps", num_comps);
    current_statement__ = 243;
    validate_non_negative_index("K_const", "n1", n1);
    current_statement__ = 244;
    validate_non_negative_index("K_const", "n2", n2);
    std::vector<Eigen::Matrix<local_scalar_t__, -1, -1>> K_const;
    K_const = std::vector<Eigen::Matrix<local_scalar_t__, -1, -1>>(num_comps, Eigen::Matrix<local_scalar_t__, -1, -1>(n1, n2));
    stan::math::fill(K_const, DUMMY_VAR__);
    
    current_statement__ = 265;
    for (int j = 1; j <= num_comps; ++j) {
      current_statement__ = 246;
      validate_non_negative_index("K", "n1", n1);
      current_statement__ = 247;
      validate_non_negative_index("K", "n2", n2);
      Eigen::Matrix<local_scalar_t__, -1, -1> K;
      K = Eigen::Matrix<local_scalar_t__, -1, -1>(n1, n2);
      stan::math::fill(K, DUMMY_VAR__);
      
      std::vector<int> opts;
      opts = std::vector<int>(9, std::numeric_limits<int>::min());
      
      current_statement__ = 249;
      assign(opts, nil_index_list(), components[(j - 1)],
        "assigning variable opts");
      int ctype;
      ctype = std::numeric_limits<int>::min();
      
      current_statement__ = 250;
      ctype = opts[(1 - 1)];
      int ktype;
      ktype = std::numeric_limits<int>::min();
      
      current_statement__ = 251;
      ktype = opts[(2 - 1)];
      int idx_cat;
      idx_cat = std::numeric_limits<int>::min();
      
      current_statement__ = 252;
      idx_cat = opts[(8 - 1)];
      int idx_cont;
      idx_cont = std::numeric_limits<int>::min();
      
      current_statement__ = 253;
      idx_cont = opts[(9 - 1)];
      current_statement__ = 258;
      if (logical_neq(idx_cont, 0)) {
        current_statement__ = 256;
        assign(K, nil_index_list(),
          STAN_kernel_const(x1_mask[(idx_cont - 1)], x2_mask[(idx_cont - 1)],
            2, 0, pstream__), "assigning variable K");
      } else {
        current_statement__ = 254;
        assign(K, nil_index_list(), rep_matrix(1, n1, n2),
          "assigning variable K");
      }
      current_statement__ = 262;
      if ((primitive_value(logical_eq(ctype, 0)) || primitive_value(
          logical_eq(ctype, 2)))) {
        int M;
        M = std::numeric_limits<int>::min();
        
        current_statement__ = 259;
        M = num_levels[(idx_cat - 1)];
        current_statement__ = 260;
        assign(K, nil_index_list(),
          elt_multiply(stan::model::deep_copy(K),
            STAN_kernel_const(x1[(idx_cat - 1)], x2[(idx_cat - 1)], ktype,
              M, pstream__)), "assigning variable K");
      } 
      current_statement__ = 263;
      assign(K_const, cons_list(index_uni(j), nil_index_list()), K,
        "assigning variable K_const");}
    current_statement__ = 266;
    return K_const;
  } catch (const std::exception& e) {
    stan::lang::rethrow_located(e, locations_array__[current_statement__]);
      // Next line prevents compiler griping about no return
      throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***"); 
  }
  
}
struct STAN_kernel_const_all_functor__ {
std::vector<Eigen::Matrix<double, -1, -1>>
operator()(const int& n1, const int& n2,
           const std::vector<std::vector<int>>& x1,
           const std::vector<std::vector<int>>& x2,
           const std::vector<std::vector<int>>& x1_mask,
           const std::vector<std::vector<int>>& x2_mask,
           const std::vector<int>& num_levels,
           const std::vector<std::vector<int>>& components,
           std::ostream* pstream__)  const 
{
return STAN_kernel_const_all(n1, n2, x1, x2, x1_mask, x2_mask, num_levels,
         components, pstream__);
}
};
template <typename T0__, typename T1__, typename T2__, typename T3__>
Eigen::Matrix<stan::promote_args_t<stan::value_type_t<T0__>, stan::value_type_t<T1__>,
T2__,
T3__>, -1, -1>
STAN_kernel_eq(const T0__& x1_arg__, const T1__& x2_arg__, const T2__& alpha,
               const T3__& ell, std::ostream* pstream__) {
  using local_scalar_t__ = stan::promote_args_t<stan::value_type_t<T0__>,
          stan::value_type_t<T1__>,
          T2__,
          T3__>;
  const auto& x1 = to_ref(x1_arg__);
  const auto& x2 = to_ref(x2_arg__);
  const static bool propto__ = true;
  (void) propto__;
  local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
  (void) DUMMY_VAR__;  // suppress unused var warning
  
  try {
    current_statement__ = 268;
    return gp_exp_quad_cov(to_array_1d(x1), to_array_1d(x2), alpha, ell);
  } catch (const std::exception& e) {
    stan::lang::rethrow_located(e, locations_array__[current_statement__]);
      // Next line prevents compiler griping about no return
      throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***"); 
  }
  
}
struct STAN_kernel_eq_functor__ {
template <typename T0__, typename T1__, typename T2__, typename T3__>
Eigen::Matrix<stan::promote_args_t<stan::value_type_t<T0__>, stan::value_type_t<T1__>,
T2__,
T3__>, -1, -1>
operator()(const T0__& x1, const T1__& x2, const T2__& alpha,
           const T3__& ell, std::ostream* pstream__)  const 
{
return STAN_kernel_eq(x1, x2, alpha, ell, pstream__);
}
};
template <typename T0__, typename T1__, typename T2__>
Eigen::Matrix<stan::promote_args_t<stan::value_type_t<T0__>, stan::value_type_t<T1__>,
T2__>, -1, -1>
STAN_kernel_varmask(const T0__& x1_arg__, const T1__& x2_arg__,
                    const T2__& steepness,
                    const std::vector<double>& vm_params,
                    std::ostream* pstream__) {
  using local_scalar_t__ = stan::promote_args_t<stan::value_type_t<T0__>,
          stan::value_type_t<T1__>,
          T2__>;
  const auto& x1 = to_ref(x1_arg__);
  const auto& x2 = to_ref(x2_arg__);
  const static bool propto__ = true;
  (void) propto__;
  local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
  (void) DUMMY_VAR__;  // suppress unused var warning
  
  try {
    local_scalar_t__ a;
    a = DUMMY_VAR__;
    
    current_statement__ = 270;
    a = (steepness * vm_params[(2 - 1)]);
    local_scalar_t__ r;
    r = DUMMY_VAR__;
    
    current_statement__ = 271;
    r = (inv(a) * logit(vm_params[(1 - 1)]));
    current_statement__ = 272;
    return multiply(
             to_matrix(
               to_matrix(STAN_var_mask(subtract(x1, r), a, pstream__))),
             transpose(
               to_matrix(STAN_var_mask(subtract(x2, r), a, pstream__))));
  } catch (const std::exception& e) {
    stan::lang::rethrow_located(e, locations_array__[current_statement__]);
      // Next line prevents compiler griping about no return
      throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***"); 
  }
  
}
struct STAN_kernel_varmask_functor__ {
template <typename T0__, typename T1__, typename T2__>
Eigen::Matrix<stan::promote_args_t<stan::value_type_t<T0__>, stan::value_type_t<T1__>,
T2__>, -1, -1>
operator()(const T0__& x1, const T1__& x2, const T2__& steepness,
           const std::vector<double>& vm_params, std::ostream* pstream__)  const 
{
return STAN_kernel_varmask(x1, x2, steepness, vm_params, pstream__);
}
};
template <typename T0__>
Eigen::Matrix<stan::promote_args_t<stan::value_type_t<T0__>>, -1, -1>
STAN_kernel_beta(const T0__& beta_arg__, const std::vector<int>& idx1_expand,
                 const std::vector<int>& idx2_expand, std::ostream* pstream__) {
  using local_scalar_t__ = stan::promote_args_t<stan::value_type_t<T0__>>;
  const auto& beta = to_ref(beta_arg__);
  const static bool propto__ = true;
  (void) propto__;
  local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
  (void) DUMMY_VAR__;  // suppress unused var warning
  
  try {
    current_statement__ = 274;
    return multiply(
             to_matrix(
               STAN_expand(stan::math::sqrt(beta), idx1_expand, pstream__)),
             transpose(
               to_matrix(
                 STAN_expand(stan::math::sqrt(beta), idx2_expand, pstream__))));
  } catch (const std::exception& e) {
    stan::lang::rethrow_located(e, locations_array__[current_statement__]);
      // Next line prevents compiler griping about no return
      throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***"); 
  }
  
}
struct STAN_kernel_beta_functor__ {
template <typename T0__>
Eigen::Matrix<stan::promote_args_t<stan::value_type_t<T0__>>, -1, -1>
operator()(const T0__& beta, const std::vector<int>& idx1_expand,
           const std::vector<int>& idx2_expand, std::ostream* pstream__)  const 
{
return STAN_kernel_beta(beta, idx1_expand, idx2_expand, pstream__);
}
};
template <typename T8__, typename T9__, typename T10__, typename T11__,
typename T12__>
std::vector<Eigen::Matrix<stan::promote_args_t<T8__, T9__, T10__, T11__,
T12__>, -1, -1>>
STAN_kernel_all(const int& n1, const int& n2,
                const std::vector<Eigen::Matrix<double, -1, -1>>& K_const,
                const std::vector<std::vector<int>>& components,
                const std::vector<Eigen::Matrix<double, -1, 1>>& x1,
                const std::vector<Eigen::Matrix<double, -1, 1>>& x2,
                const std::vector<Eigen::Matrix<double, -1, 1>>& x1_unnorm,
                const std::vector<Eigen::Matrix<double, -1, 1>>& x2_unnorm,
                const std::vector<T8__>& alpha, const std::vector<T9__>& ell,
                const std::vector<T10__>& wrp,
                const std::vector<Eigen::Matrix<T11__, -1, 1>>& beta,
                const std::vector<Eigen::Matrix<T12__, -1, 1>>& teff,
                const std::vector<double>& vm_params,
                const std::vector<int>& idx1_expand,
                const std::vector<int>& idx2_expand,
                const std::vector<Eigen::Matrix<double, -1, 1>>& teff_zero,
                std::ostream* pstream__) {
  using local_scalar_t__ = stan::promote_args_t<T8__,
          T9__,
          T10__,
          T11__,
          T12__>;
  const static bool propto__ = true;
  (void) propto__;
  local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
  (void) DUMMY_VAR__;  // suppress unused var warning
  
  try {
    int idx_ell;
    idx_ell = std::numeric_limits<int>::min();
    
    current_statement__ = 276;
    idx_ell = 0;
    int idx_wrp;
    idx_wrp = std::numeric_limits<int>::min();
    
    current_statement__ = 277;
    idx_wrp = 0;
    int idx_alpha;
    idx_alpha = std::numeric_limits<int>::min();
    
    current_statement__ = 278;
    idx_alpha = 0;
    int num_comps;
    num_comps = std::numeric_limits<int>::min();
    
    current_statement__ = 279;
    num_comps = stan::math::size(components);
    current_statement__ = 280;
    validate_non_negative_index("KX", "num_comps", num_comps);
    current_statement__ = 281;
    validate_non_negative_index("KX", "n1", n1);
    current_statement__ = 282;
    validate_non_negative_index("KX", "n2", n2);
    std::vector<Eigen::Matrix<local_scalar_t__, -1, -1>> KX;
    KX = std::vector<Eigen::Matrix<local_scalar_t__, -1, -1>>(num_comps, Eigen::Matrix<local_scalar_t__, -1, -1>(n1, n2));
    stan::math::fill(KX, DUMMY_VAR__);
    
    current_statement__ = 333;
    for (int j = 1; j <= num_comps; ++j) {
      current_statement__ = 284;
      validate_non_negative_index("K", "n1", n1);
      current_statement__ = 285;
      validate_non_negative_index("K", "n2", n2);
      Eigen::Matrix<local_scalar_t__, -1, -1> K;
      K = Eigen::Matrix<local_scalar_t__, -1, -1>(n1, n2);
      stan::math::fill(K, DUMMY_VAR__);
      
      current_statement__ = 286;
      assign(K, nil_index_list(), K_const[(j - 1)], "assigning variable K");
      current_statement__ = 287;
      validate_non_negative_index("X1", "n1", n1);
      Eigen::Matrix<local_scalar_t__, -1, 1> X1;
      X1 = Eigen::Matrix<local_scalar_t__, -1, 1>(n1);
      stan::math::fill(X1, DUMMY_VAR__);
      
      current_statement__ = 289;
      validate_non_negative_index("X2", "n2", n2);
      Eigen::Matrix<local_scalar_t__, -1, 1> X2;
      X2 = Eigen::Matrix<local_scalar_t__, -1, 1>(n2);
      stan::math::fill(X2, DUMMY_VAR__);
      
      std::vector<int> opts;
      opts = std::vector<int>(9, std::numeric_limits<int>::min());
      
      current_statement__ = 291;
      assign(opts, nil_index_list(), components[(j - 1)],
        "assigning variable opts");
      int ctype;
      ctype = std::numeric_limits<int>::min();
      
      current_statement__ = 292;
      ctype = opts[(1 - 1)];
      int idx_cont;
      idx_cont = std::numeric_limits<int>::min();
      
      current_statement__ = 293;
      idx_cont = opts[(9 - 1)];
      int is_heter;
      is_heter = std::numeric_limits<int>::min();
      
      current_statement__ = 294;
      is_heter = opts[(4 - 1)];
      int is_warped;
      is_warped = std::numeric_limits<int>::min();
      
      current_statement__ = 295;
      is_warped = opts[(5 - 1)];
      int is_var_masked;
      is_var_masked = std::numeric_limits<int>::min();
      
      current_statement__ = 296;
      is_var_masked = opts[(6 - 1)];
      int is_uncrt;
      is_uncrt = std::numeric_limits<int>::min();
      
      current_statement__ = 297;
      is_uncrt = opts[(7 - 1)];
      current_statement__ = 306;
      if (logical_neq(ctype, 0)) {
        current_statement__ = 304;
        if (is_warped) {
          current_statement__ = 301;
          assign(X1, nil_index_list(), x1_unnorm[(idx_cont - 1)],
            "assigning variable X1");
          current_statement__ = 302;
          assign(X2, nil_index_list(), x2_unnorm[(idx_cont - 1)],
            "assigning variable X2");
        } else {
          current_statement__ = 298;
          assign(X1, nil_index_list(), x1[(idx_cont - 1)],
            "assigning variable X1");
          current_statement__ = 299;
          assign(X2, nil_index_list(), x2[(idx_cont - 1)],
            "assigning variable X2");
        }
      } 
      current_statement__ = 320;
      if (is_warped) {
        local_scalar_t__ s;
        s = DUMMY_VAR__;
        
        current_statement__ = 308;
        idx_wrp = (idx_wrp + 1);
        current_statement__ = 312;
        if (is_uncrt) {
          current_statement__ = 309;
          assign(X1, nil_index_list(),
            STAN_edit_x_cont(stan::model::deep_copy(X1), idx1_expand,
              teff_zero[(1 - 1)], teff[(1 - 1)], pstream__),
            "assigning variable X1");
          current_statement__ = 310;
          assign(X2, nil_index_list(),
            STAN_edit_x_cont(stan::model::deep_copy(X2), idx2_expand,
              teff_zero[(1 - 1)], teff[(1 - 1)], pstream__),
            "assigning variable X2");
        } 
        current_statement__ = 313;
        s = wrp[(idx_wrp - 1)];
        current_statement__ = 316;
        if (is_var_masked) {
          current_statement__ = 314;
          assign(K, nil_index_list(),
            elt_multiply(stan::model::deep_copy(K),
              STAN_kernel_varmask(X1, X2, s, vm_params, pstream__)),
            "assigning variable K");
        } 
        current_statement__ = 317;
        assign(X1, nil_index_list(),
          STAN_warp_input(stan::model::deep_copy(X1), s, pstream__),
          "assigning variable X1");
        current_statement__ = 318;
        assign(X2, nil_index_list(),
          STAN_warp_input(stan::model::deep_copy(X2), s, pstream__),
          "assigning variable X2");
      } 
      current_statement__ = 321;
      idx_alpha = (idx_alpha + 1);
      current_statement__ = 327;
      if (logical_neq(ctype, 0)) {
        current_statement__ = 324;
        idx_ell = (idx_ell + 1);
        current_statement__ = 325;
        assign(K, nil_index_list(),
          elt_multiply(stan::model::deep_copy(K),
            STAN_kernel_eq(X1, X2, alpha[(idx_alpha - 1)],
              ell[(idx_ell - 1)], pstream__)), "assigning variable K");
      } else {
        current_statement__ = 322;
        assign(K, nil_index_list(),
          multiply(square(alpha[(idx_alpha - 1)]), stan::model::deep_copy(K)),
          "assigning variable K");
      }
      current_statement__ = 330;
      if (is_heter) {
        current_statement__ = 328;
        assign(K, nil_index_list(),
          elt_multiply(stan::model::deep_copy(K),
            STAN_kernel_beta(beta[(1 - 1)], idx1_expand,
              idx2_expand, pstream__)), "assigning variable K");
      } 
      current_statement__ = 331;
      assign(KX, cons_list(index_uni(j), nil_index_list()), K,
        "assigning variable KX");}
    current_statement__ = 334;
    return KX;
  } catch (const std::exception& e) {
    stan::lang::rethrow_located(e, locations_array__[current_statement__]);
      // Next line prevents compiler griping about no return
      throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***"); 
  }
  
}
struct STAN_kernel_all_functor__ {
template <typename T8__, typename T9__, typename T10__, typename T11__,
typename T12__>
std::vector<Eigen::Matrix<stan::promote_args_t<T8__, T9__, T10__, T11__,
T12__>, -1, -1>>
operator()(const int& n1, const int& n2,
           const std::vector<Eigen::Matrix<double, -1, -1>>& K_const,
           const std::vector<std::vector<int>>& components,
           const std::vector<Eigen::Matrix<double, -1, 1>>& x1,
           const std::vector<Eigen::Matrix<double, -1, 1>>& x2,
           const std::vector<Eigen::Matrix<double, -1, 1>>& x1_unnorm,
           const std::vector<Eigen::Matrix<double, -1, 1>>& x2_unnorm,
           const std::vector<T8__>& alpha, const std::vector<T9__>& ell,
           const std::vector<T10__>& wrp,
           const std::vector<Eigen::Matrix<T11__, -1, 1>>& beta,
           const std::vector<Eigen::Matrix<T12__, -1, 1>>& teff,
           const std::vector<double>& vm_params,
           const std::vector<int>& idx1_expand,
           const std::vector<int>& idx2_expand,
           const std::vector<Eigen::Matrix<double, -1, 1>>& teff_zero,
           std::ostream* pstream__)  const 
{
return STAN_kernel_all(n1, n2, K_const, components, x1, x2, x1_unnorm,
         x2_unnorm, alpha, ell, wrp, beta, teff, vm_params, idx1_expand,
         idx2_expand, teff_zero, pstream__);
}
};
#include <stan_meta_header.hpp>
class model_lgp final : public model_base_crtp<model_lgp> {
private:
  int is_verbose;
  int is_likelihood_skipped;
  int num_obs;
  int num_cov_cont;
  int num_cov_cat;
  int num_comps;
  int num_ell;
  int num_ns;
  int num_heter;
  int num_uncrt;
  int num_bt;
  std::vector<std::vector<int>> components;
  std::vector<Eigen::Matrix<double, -1, 1>> teff_zero;
  std::vector<Eigen::Matrix<double, -1, 1>> teff_lb;
  std::vector<Eigen::Matrix<double, -1, 1>> teff_ub;
  std::vector<int> x_cat_num_levels;
  double delta;
  std::vector<double> vm_params;
  std::vector<Eigen::Matrix<double, -1, 1>> x_cont;
  std::vector<Eigen::Matrix<double, -1, 1>> x_cont_unnorm;
  std::vector<std::vector<int>> x_cont_mask;
  std::vector<std::vector<int>> x_cat;
  std::vector<int> idx_expand;
  std::vector<std::vector<int>> prior_alpha;
  std::vector<std::vector<int>> prior_ell;
  std::vector<std::vector<int>> prior_wrp;
  std::vector<std::vector<int>> prior_teff;
  std::vector<std::vector<double>> hyper_alpha;
  std::vector<std::vector<double>> hyper_ell;
  std::vector<std::vector<double>> hyper_wrp;
  std::vector<std::vector<double>> hyper_teff;
  std::vector<std::vector<double>> hyper_beta;
  Eigen::Matrix<double, -1, 1> y_norm;
  std::vector<std::vector<int>> prior_sigma;
  std::vector<std::vector<double>> hyper_sigma;
  Eigen::Matrix<double, -1, 1> m0;
  std::vector<Eigen::Matrix<double, -1, -1>> K_const;
  Eigen::Matrix<double, -1, 1> delta_vec;
  int beta_1dim__;
  int teff_raw_1dim__;
  int teff_1dim__;
 
public:
  ~model_lgp() { }
  
  inline std::string model_name() const final { return "model_lgp"; }
  inline std::vector<std::string> model_compile_info() const noexcept {
    return std::vector<std::string>{"stanc_version = stanc3 v2.26.1-4-gd72b68b7-dirty", "stancflags = "};
  }
  
  
  model_lgp(stan::io::var_context& context__, unsigned int random_seed__ = 0,
            std::ostream* pstream__ = nullptr) : model_base_crtp(0) {
    using local_scalar_t__ = double ;
    boost::ecuyer1988 base_rng__ = 
        stan::services::util::create_rng(random_seed__, 0);
    (void) base_rng__;  // suppress unused var warning
    static const char* function__ = "model_lgp_namespace::model_lgp";
    (void) function__;  // suppress unused var warning
    local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
    (void) DUMMY_VAR__;  // suppress unused var warning
    
    try {
      int pos__;
      pos__ = std::numeric_limits<int>::min();
      
      pos__ = 1;
      current_statement__ = 48;
      context__.validate_dims("data initialization","is_verbose","int",
          context__.to_vec());
      is_verbose = std::numeric_limits<int>::min();
      
      current_statement__ = 48;
      is_verbose = context__.vals_i("is_verbose")[(1 - 1)];
      current_statement__ = 48;
      current_statement__ = 48;
      check_greater_or_equal(function__, "is_verbose", is_verbose, 0);
      current_statement__ = 48;
      current_statement__ = 48;
      check_less_or_equal(function__, "is_verbose", is_verbose, 1);
      current_statement__ = 49;
      context__.validate_dims("data initialization","is_likelihood_skipped",
          "int",context__.to_vec());
      is_likelihood_skipped = std::numeric_limits<int>::min();
      
      current_statement__ = 49;
      is_likelihood_skipped = context__.vals_i("is_likelihood_skipped")[
          (1 - 1)];
      current_statement__ = 49;
      current_statement__ = 49;
      check_greater_or_equal(function__, "is_likelihood_skipped",
                             is_likelihood_skipped, 0);
      current_statement__ = 49;
      current_statement__ = 49;
      check_less_or_equal(function__, "is_likelihood_skipped",
                          is_likelihood_skipped, 1);
      current_statement__ = 50;
      context__.validate_dims("data initialization","num_obs","int",
          context__.to_vec());
      num_obs = std::numeric_limits<int>::min();
      
      current_statement__ = 50;
      num_obs = context__.vals_i("num_obs")[(1 - 1)];
      current_statement__ = 50;
      current_statement__ = 50;
      check_greater_or_equal(function__, "num_obs", num_obs, 0);
      current_statement__ = 51;
      context__.validate_dims("data initialization","num_cov_cont","int",
          context__.to_vec());
      num_cov_cont = std::numeric_limits<int>::min();
      
      current_statement__ = 51;
      num_cov_cont = context__.vals_i("num_cov_cont")[(1 - 1)];
      current_statement__ = 51;
      current_statement__ = 51;
      check_greater_or_equal(function__, "num_cov_cont", num_cov_cont, 0);
      current_statement__ = 52;
      context__.validate_dims("data initialization","num_cov_cat","int",
          context__.to_vec());
      num_cov_cat = std::numeric_limits<int>::min();
      
      current_statement__ = 52;
      num_cov_cat = context__.vals_i("num_cov_cat")[(1 - 1)];
      current_statement__ = 52;
      current_statement__ = 52;
      check_greater_or_equal(function__, "num_cov_cat", num_cov_cat, 0);
      current_statement__ = 53;
      context__.validate_dims("data initialization","num_comps","int",
          context__.to_vec());
      num_comps = std::numeric_limits<int>::min();
      
      current_statement__ = 53;
      num_comps = context__.vals_i("num_comps")[(1 - 1)];
      current_statement__ = 53;
      current_statement__ = 53;
      check_greater_or_equal(function__, "num_comps", num_comps, 1);
      current_statement__ = 54;
      context__.validate_dims("data initialization","num_ell","int",
          context__.to_vec());
      num_ell = std::numeric_limits<int>::min();
      
      current_statement__ = 54;
      num_ell = context__.vals_i("num_ell")[(1 - 1)];
      current_statement__ = 54;
      current_statement__ = 54;
      check_greater_or_equal(function__, "num_ell", num_ell, 0);
      current_statement__ = 55;
      context__.validate_dims("data initialization","num_ns","int",
          context__.to_vec());
      num_ns = std::numeric_limits<int>::min();
      
      current_statement__ = 55;
      num_ns = context__.vals_i("num_ns")[(1 - 1)];
      current_statement__ = 55;
      current_statement__ = 55;
      check_greater_or_equal(function__, "num_ns", num_ns, 0);
      current_statement__ = 56;
      context__.validate_dims("data initialization","num_heter","int",
          context__.to_vec());
      num_heter = std::numeric_limits<int>::min();
      
      current_statement__ = 56;
      num_heter = context__.vals_i("num_heter")[(1 - 1)];
      current_statement__ = 56;
      current_statement__ = 56;
      check_greater_or_equal(function__, "num_heter", num_heter, 0);
      current_statement__ = 57;
      context__.validate_dims("data initialization","num_uncrt","int",
          context__.to_vec());
      num_uncrt = std::numeric_limits<int>::min();
      
      current_statement__ = 57;
      num_uncrt = context__.vals_i("num_uncrt")[(1 - 1)];
      current_statement__ = 57;
      current_statement__ = 57;
      check_greater_or_equal(function__, "num_uncrt", num_uncrt, 0);
      current_statement__ = 58;
      context__.validate_dims("data initialization","num_bt","int",
          context__.to_vec());
      num_bt = std::numeric_limits<int>::min();
      
      current_statement__ = 58;
      num_bt = context__.vals_i("num_bt")[(1 - 1)];
      current_statement__ = 58;
      current_statement__ = 58;
      check_greater_or_equal(function__, "num_bt", num_bt, 0);
      current_statement__ = 59;
      validate_non_negative_index("components", "num_comps", num_comps);
      current_statement__ = 60;
      context__.validate_dims("data initialization","components","int",
          context__.to_vec(num_comps, 9));
      components = std::vector<std::vector<int>>(num_comps, std::vector<int>(9, std::numeric_limits<int>::min()));
      
      {
        std::vector<int> components_flat__;
        current_statement__ = 60;
        assign(components_flat__, nil_index_list(),
          context__.vals_i("components"),
          "assigning variable components_flat__");
        current_statement__ = 60;
        pos__ = 1;
        current_statement__ = 60;
        for (int sym1__ = 1; sym1__ <= 9; ++sym1__) {
          current_statement__ = 60;
          for (int sym2__ = 1; sym2__ <= num_comps; ++sym2__) {
            current_statement__ = 60;
            assign(components,
              cons_list(index_uni(sym2__),
                cons_list(index_uni(sym1__), nil_index_list())),
              components_flat__[(pos__ - 1)], "assigning variable components");
            current_statement__ = 60;
            pos__ = (pos__ + 1);}}
      }
      current_statement__ = 60;
      for (int sym1__ = 1; sym1__ <= num_comps; ++sym1__) {
        current_statement__ = 60;
        for (int sym2__ = 1; sym2__ <= 9; ++sym2__) {
          current_statement__ = 60;
          current_statement__ = 60;
          check_greater_or_equal(function__, "components[sym1__, sym2__]",
                                 components[(sym1__ - 1)][(sym2__ - 1)], 0);}
      }
      current_statement__ = 61;
      validate_non_negative_index("teff_zero", "num_uncrt > 0",
                                  logical_gt(num_uncrt, 0));
      current_statement__ = 62;
      validate_non_negative_index("teff_zero", "num_bt", num_bt);
      current_statement__ = 63;
      context__.validate_dims("data initialization","teff_zero","double",
          context__.to_vec(logical_gt(num_uncrt, 0), num_bt));
      teff_zero = std::vector<Eigen::Matrix<double, -1, 1>>(logical_gt(
                                                              num_uncrt, 0), Eigen::Matrix<double, -1, 1>(num_bt));
      stan::math::fill(teff_zero, std::numeric_limits<double>::quiet_NaN());
      
      {
        std::vector<local_scalar_t__> teff_zero_flat__;
        current_statement__ = 63;
        assign(teff_zero_flat__, nil_index_list(),
          context__.vals_r("teff_zero"),
          "assigning variable teff_zero_flat__");
        current_statement__ = 63;
        pos__ = 1;
        current_statement__ = 63;
        for (int sym1__ = 1; sym1__ <= num_bt; ++sym1__) {
          current_statement__ = 63;
          for (int sym2__ = 1; sym2__ <= logical_gt(num_uncrt, 0); ++sym2__) {
            current_statement__ = 63;
            assign(teff_zero,
              cons_list(index_uni(sym2__),
                cons_list(index_uni(sym1__), nil_index_list())),
              teff_zero_flat__[(pos__ - 1)], "assigning variable teff_zero");
            current_statement__ = 63;
            pos__ = (pos__ + 1);}}
      }
      current_statement__ = 64;
      validate_non_negative_index("teff_lb", "num_uncrt > 0",
                                  logical_gt(num_uncrt, 0));
      current_statement__ = 65;
      validate_non_negative_index("teff_lb", "num_bt", num_bt);
      current_statement__ = 66;
      context__.validate_dims("data initialization","teff_lb","double",
          context__.to_vec(logical_gt(num_uncrt, 0), num_bt));
      teff_lb = std::vector<Eigen::Matrix<double, -1, 1>>(logical_gt(
                                                            num_uncrt, 0), Eigen::Matrix<double, -1, 1>(num_bt));
      stan::math::fill(teff_lb, std::numeric_limits<double>::quiet_NaN());
      
      {
        std::vector<local_scalar_t__> teff_lb_flat__;
        current_statement__ = 66;
        assign(teff_lb_flat__, nil_index_list(), context__.vals_r("teff_lb"),
          "assigning variable teff_lb_flat__");
        current_statement__ = 66;
        pos__ = 1;
        current_statement__ = 66;
        for (int sym1__ = 1; sym1__ <= num_bt; ++sym1__) {
          current_statement__ = 66;
          for (int sym2__ = 1; sym2__ <= logical_gt(num_uncrt, 0); ++sym2__) {
            current_statement__ = 66;
            assign(teff_lb,
              cons_list(index_uni(sym2__),
                cons_list(index_uni(sym1__), nil_index_list())),
              teff_lb_flat__[(pos__ - 1)], "assigning variable teff_lb");
            current_statement__ = 66;
            pos__ = (pos__ + 1);}}
      }
      current_statement__ = 67;
      validate_non_negative_index("teff_ub", "num_uncrt > 0",
                                  logical_gt(num_uncrt, 0));
      current_statement__ = 68;
      validate_non_negative_index("teff_ub", "num_bt", num_bt);
      current_statement__ = 69;
      context__.validate_dims("data initialization","teff_ub","double",
          context__.to_vec(logical_gt(num_uncrt, 0), num_bt));
      teff_ub = std::vector<Eigen::Matrix<double, -1, 1>>(logical_gt(
                                                            num_uncrt, 0), Eigen::Matrix<double, -1, 1>(num_bt));
      stan::math::fill(teff_ub, std::numeric_limits<double>::quiet_NaN());
      
      {
        std::vector<local_scalar_t__> teff_ub_flat__;
        current_statement__ = 69;
        assign(teff_ub_flat__, nil_index_list(), context__.vals_r("teff_ub"),
          "assigning variable teff_ub_flat__");
        current_statement__ = 69;
        pos__ = 1;
        current_statement__ = 69;
        for (int sym1__ = 1; sym1__ <= num_bt; ++sym1__) {
          current_statement__ = 69;
          for (int sym2__ = 1; sym2__ <= logical_gt(num_uncrt, 0); ++sym2__) {
            current_statement__ = 69;
            assign(teff_ub,
              cons_list(index_uni(sym2__),
                cons_list(index_uni(sym1__), nil_index_list())),
              teff_ub_flat__[(pos__ - 1)], "assigning variable teff_ub");
            current_statement__ = 69;
            pos__ = (pos__ + 1);}}
      }
      current_statement__ = 70;
      validate_non_negative_index("x_cat_num_levels", "num_cov_cat",
                                  num_cov_cat);
      current_statement__ = 71;
      context__.validate_dims("data initialization","x_cat_num_levels","int",
          context__.to_vec(num_cov_cat));
      x_cat_num_levels = std::vector<int>(num_cov_cat, std::numeric_limits<int>::min());
      
      current_statement__ = 71;
      assign(x_cat_num_levels, nil_index_list(),
        context__.vals_i("x_cat_num_levels"),
        "assigning variable x_cat_num_levels");
      current_statement__ = 71;
      for (int sym1__ = 1; sym1__ <= num_cov_cat; ++sym1__) {
        current_statement__ = 71;
        current_statement__ = 71;
        check_greater_or_equal(function__, "x_cat_num_levels[sym1__]",
                               x_cat_num_levels[(sym1__ - 1)], 0);}
      current_statement__ = 72;
      context__.validate_dims("data initialization","delta","double",
          context__.to_vec());
      delta = std::numeric_limits<double>::quiet_NaN();
      
      current_statement__ = 72;
      delta = context__.vals_r("delta")[(1 - 1)];
      current_statement__ = 73;
      context__.validate_dims("data initialization","vm_params","double",
          context__.to_vec(2));
      vm_params = std::vector<double>(2, std::numeric_limits<double>::quiet_NaN());
      
      current_statement__ = 73;
      assign(vm_params, nil_index_list(), context__.vals_r("vm_params"),
        "assigning variable vm_params");
      current_statement__ = 74;
      validate_non_negative_index("x_cont", "num_cov_cont", num_cov_cont);
      current_statement__ = 75;
      validate_non_negative_index("x_cont", "num_obs", num_obs);
      current_statement__ = 76;
      context__.validate_dims("data initialization","x_cont","double",
          context__.to_vec(num_cov_cont, num_obs));
      x_cont = std::vector<Eigen::Matrix<double, -1, 1>>(num_cov_cont, Eigen::Matrix<double, -1, 1>(num_obs));
      stan::math::fill(x_cont, std::numeric_limits<double>::quiet_NaN());
      
      {
        std::vector<local_scalar_t__> x_cont_flat__;
        current_statement__ = 76;
        assign(x_cont_flat__, nil_index_list(), context__.vals_r("x_cont"),
          "assigning variable x_cont_flat__");
        current_statement__ = 76;
        pos__ = 1;
        current_statement__ = 76;
        for (int sym1__ = 1; sym1__ <= num_obs; ++sym1__) {
          current_statement__ = 76;
          for (int sym2__ = 1; sym2__ <= num_cov_cont; ++sym2__) {
            current_statement__ = 76;
            assign(x_cont,
              cons_list(index_uni(sym2__),
                cons_list(index_uni(sym1__), nil_index_list())),
              x_cont_flat__[(pos__ - 1)], "assigning variable x_cont");
            current_statement__ = 76;
            pos__ = (pos__ + 1);}}
      }
      current_statement__ = 77;
      validate_non_negative_index("x_cont_unnorm", "num_cov_cont",
                                  num_cov_cont);
      current_statement__ = 78;
      validate_non_negative_index("x_cont_unnorm", "num_obs", num_obs);
      current_statement__ = 79;
      context__.validate_dims("data initialization","x_cont_unnorm","double",
          context__.to_vec(num_cov_cont, num_obs));
      x_cont_unnorm = std::vector<Eigen::Matrix<double, -1, 1>>(num_cov_cont, Eigen::Matrix<double, -1, 1>(num_obs));
      stan::math::fill(x_cont_unnorm, std::numeric_limits<double>::quiet_NaN());
      
      {
        std::vector<local_scalar_t__> x_cont_unnorm_flat__;
        current_statement__ = 79;
        assign(x_cont_unnorm_flat__, nil_index_list(),
          context__.vals_r("x_cont_unnorm"),
          "assigning variable x_cont_unnorm_flat__");
        current_statement__ = 79;
        pos__ = 1;
        current_statement__ = 79;
        for (int sym1__ = 1; sym1__ <= num_obs; ++sym1__) {
          current_statement__ = 79;
          for (int sym2__ = 1; sym2__ <= num_cov_cont; ++sym2__) {
            current_statement__ = 79;
            assign(x_cont_unnorm,
              cons_list(index_uni(sym2__),
                cons_list(index_uni(sym1__), nil_index_list())),
              x_cont_unnorm_flat__[(pos__ - 1)],
              "assigning variable x_cont_unnorm");
            current_statement__ = 79;
            pos__ = (pos__ + 1);}}
      }
      current_statement__ = 80;
      validate_non_negative_index("x_cont_mask", "num_cov_cont", num_cov_cont);
      current_statement__ = 81;
      validate_non_negative_index("x_cont_mask", "num_obs", num_obs);
      current_statement__ = 82;
      context__.validate_dims("data initialization","x_cont_mask","int",
          context__.to_vec(num_cov_cont, num_obs));
      x_cont_mask = std::vector<std::vector<int>>(num_cov_cont, std::vector<int>(num_obs, std::numeric_limits<int>::min()));
      
      {
        std::vector<int> x_cont_mask_flat__;
        current_statement__ = 82;
        assign(x_cont_mask_flat__, nil_index_list(),
          context__.vals_i("x_cont_mask"),
          "assigning variable x_cont_mask_flat__");
        current_statement__ = 82;
        pos__ = 1;
        current_statement__ = 82;
        for (int sym1__ = 1; sym1__ <= num_obs; ++sym1__) {
          current_statement__ = 82;
          for (int sym2__ = 1; sym2__ <= num_cov_cont; ++sym2__) {
            current_statement__ = 82;
            assign(x_cont_mask,
              cons_list(index_uni(sym2__),
                cons_list(index_uni(sym1__), nil_index_list())),
              x_cont_mask_flat__[(pos__ - 1)],
              "assigning variable x_cont_mask");
            current_statement__ = 82;
            pos__ = (pos__ + 1);}}
      }
      current_statement__ = 83;
      validate_non_negative_index("x_cat", "num_cov_cat", num_cov_cat);
      current_statement__ = 84;
      validate_non_negative_index("x_cat", "num_obs", num_obs);
      current_statement__ = 85;
      context__.validate_dims("data initialization","x_cat","int",
          context__.to_vec(num_cov_cat, num_obs));
      x_cat = std::vector<std::vector<int>>(num_cov_cat, std::vector<int>(num_obs, std::numeric_limits<int>::min()));
      
      {
        std::vector<int> x_cat_flat__;
        current_statement__ = 85;
        assign(x_cat_flat__, nil_index_list(), context__.vals_i("x_cat"),
          "assigning variable x_cat_flat__");
        current_statement__ = 85;
        pos__ = 1;
        current_statement__ = 85;
        for (int sym1__ = 1; sym1__ <= num_obs; ++sym1__) {
          current_statement__ = 85;
          for (int sym2__ = 1; sym2__ <= num_cov_cat; ++sym2__) {
            current_statement__ = 85;
            assign(x_cat,
              cons_list(index_uni(sym2__),
                cons_list(index_uni(sym1__), nil_index_list())),
              x_cat_flat__[(pos__ - 1)], "assigning variable x_cat");
            current_statement__ = 85;
            pos__ = (pos__ + 1);}}
      }
      current_statement__ = 86;
      validate_non_negative_index("idx_expand", "num_obs", num_obs);
      current_statement__ = 87;
      context__.validate_dims("data initialization","idx_expand","int",
          context__.to_vec(num_obs));
      idx_expand = std::vector<int>(num_obs, std::numeric_limits<int>::min());
      
      current_statement__ = 87;
      assign(idx_expand, nil_index_list(), context__.vals_i("idx_expand"),
        "assigning variable idx_expand");
      current_statement__ = 87;
      for (int sym1__ = 1; sym1__ <= num_obs; ++sym1__) {
        current_statement__ = 87;
        current_statement__ = 87;
        check_greater_or_equal(function__, "idx_expand[sym1__]",
                               idx_expand[(sym1__ - 1)], 1);}
      current_statement__ = 87;
      for (int sym1__ = 1; sym1__ <= num_obs; ++sym1__) {
        current_statement__ = 87;
        current_statement__ = 87;
        check_less_or_equal(function__, "idx_expand[sym1__]",
                            idx_expand[(sym1__ - 1)], (num_bt + 1));}
      current_statement__ = 88;
      validate_non_negative_index("prior_alpha", "num_comps", num_comps);
      current_statement__ = 89;
      context__.validate_dims("data initialization","prior_alpha","int",
          context__.to_vec(num_comps, 2));
      prior_alpha = std::vector<std::vector<int>>(num_comps, std::vector<int>(2, std::numeric_limits<int>::min()));
      
      {
        std::vector<int> prior_alpha_flat__;
        current_statement__ = 89;
        assign(prior_alpha_flat__, nil_index_list(),
          context__.vals_i("prior_alpha"),
          "assigning variable prior_alpha_flat__");
        current_statement__ = 89;
        pos__ = 1;
        current_statement__ = 89;
        for (int sym1__ = 1; sym1__ <= 2; ++sym1__) {
          current_statement__ = 89;
          for (int sym2__ = 1; sym2__ <= num_comps; ++sym2__) {
            current_statement__ = 89;
            assign(prior_alpha,
              cons_list(index_uni(sym2__),
                cons_list(index_uni(sym1__), nil_index_list())),
              prior_alpha_flat__[(pos__ - 1)],
              "assigning variable prior_alpha");
            current_statement__ = 89;
            pos__ = (pos__ + 1);}}
      }
      current_statement__ = 89;
      for (int sym1__ = 1; sym1__ <= num_comps; ++sym1__) {
        current_statement__ = 89;
        for (int sym2__ = 1; sym2__ <= 2; ++sym2__) {
          current_statement__ = 89;
          current_statement__ = 89;
          check_greater_or_equal(function__, "prior_alpha[sym1__, sym2__]",
                                 prior_alpha[(sym1__ - 1)][(sym2__ - 1)], 0);
        }}
      current_statement__ = 90;
      validate_non_negative_index("prior_ell", "num_ell", num_ell);
      current_statement__ = 91;
      context__.validate_dims("data initialization","prior_ell","int",
          context__.to_vec(num_ell, 2));
      prior_ell = std::vector<std::vector<int>>(num_ell, std::vector<int>(2, std::numeric_limits<int>::min()));
      
      {
        std::vector<int> prior_ell_flat__;
        current_statement__ = 91;
        assign(prior_ell_flat__, nil_index_list(),
          context__.vals_i("prior_ell"),
          "assigning variable prior_ell_flat__");
        current_statement__ = 91;
        pos__ = 1;
        current_statement__ = 91;
        for (int sym1__ = 1; sym1__ <= 2; ++sym1__) {
          current_statement__ = 91;
          for (int sym2__ = 1; sym2__ <= num_ell; ++sym2__) {
            current_statement__ = 91;
            assign(prior_ell,
              cons_list(index_uni(sym2__),
                cons_list(index_uni(sym1__), nil_index_list())),
              prior_ell_flat__[(pos__ - 1)], "assigning variable prior_ell");
            current_statement__ = 91;
            pos__ = (pos__ + 1);}}
      }
      current_statement__ = 91;
      for (int sym1__ = 1; sym1__ <= num_ell; ++sym1__) {
        current_statement__ = 91;
        for (int sym2__ = 1; sym2__ <= 2; ++sym2__) {
          current_statement__ = 91;
          current_statement__ = 91;
          check_greater_or_equal(function__, "prior_ell[sym1__, sym2__]",
                                 prior_ell[(sym1__ - 1)][(sym2__ - 1)], 0);}}
      current_statement__ = 92;
      validate_non_negative_index("prior_wrp", "num_ns", num_ns);
      current_statement__ = 93;
      context__.validate_dims("data initialization","prior_wrp","int",
          context__.to_vec(num_ns, 2));
      prior_wrp = std::vector<std::vector<int>>(num_ns, std::vector<int>(2, std::numeric_limits<int>::min()));
      
      {
        std::vector<int> prior_wrp_flat__;
        current_statement__ = 93;
        assign(prior_wrp_flat__, nil_index_list(),
          context__.vals_i("prior_wrp"),
          "assigning variable prior_wrp_flat__");
        current_statement__ = 93;
        pos__ = 1;
        current_statement__ = 93;
        for (int sym1__ = 1; sym1__ <= 2; ++sym1__) {
          current_statement__ = 93;
          for (int sym2__ = 1; sym2__ <= num_ns; ++sym2__) {
            current_statement__ = 93;
            assign(prior_wrp,
              cons_list(index_uni(sym2__),
                cons_list(index_uni(sym1__), nil_index_list())),
              prior_wrp_flat__[(pos__ - 1)], "assigning variable prior_wrp");
            current_statement__ = 93;
            pos__ = (pos__ + 1);}}
      }
      current_statement__ = 93;
      for (int sym1__ = 1; sym1__ <= num_ns; ++sym1__) {
        current_statement__ = 93;
        for (int sym2__ = 1; sym2__ <= 2; ++sym2__) {
          current_statement__ = 93;
          current_statement__ = 93;
          check_greater_or_equal(function__, "prior_wrp[sym1__, sym2__]",
                                 prior_wrp[(sym1__ - 1)][(sym2__ - 1)], 0);}}
      current_statement__ = 94;
      validate_non_negative_index("prior_teff", "num_uncrt > 0",
                                  logical_gt(num_uncrt, 0));
      current_statement__ = 95;
      context__.validate_dims("data initialization","prior_teff","int",
          context__.to_vec(logical_gt(num_uncrt, 0), 2));
      prior_teff = std::vector<std::vector<int>>(logical_gt(num_uncrt, 0), std::vector<int>(2, std::numeric_limits<int>::min()));
      
      {
        std::vector<int> prior_teff_flat__;
        current_statement__ = 95;
        assign(prior_teff_flat__, nil_index_list(),
          context__.vals_i("prior_teff"),
          "assigning variable prior_teff_flat__");
        current_statement__ = 95;
        pos__ = 1;
        current_statement__ = 95;
        for (int sym1__ = 1; sym1__ <= 2; ++sym1__) {
          current_statement__ = 95;
          for (int sym2__ = 1; sym2__ <= logical_gt(num_uncrt, 0); ++sym2__) {
            current_statement__ = 95;
            assign(prior_teff,
              cons_list(index_uni(sym2__),
                cons_list(index_uni(sym1__), nil_index_list())),
              prior_teff_flat__[(pos__ - 1)], "assigning variable prior_teff");
            current_statement__ = 95;
            pos__ = (pos__ + 1);}}
      }
      current_statement__ = 95;
      for (int sym1__ = 1; sym1__ <= logical_gt(num_uncrt, 0); ++sym1__) {
        current_statement__ = 95;
        for (int sym2__ = 1; sym2__ <= 2; ++sym2__) {
          current_statement__ = 95;
          current_statement__ = 95;
          check_greater_or_equal(function__, "prior_teff[sym1__, sym2__]",
                                 prior_teff[(sym1__ - 1)][(sym2__ - 1)], 0);}
      }
      current_statement__ = 96;
      validate_non_negative_index("hyper_alpha", "num_comps", num_comps);
      current_statement__ = 97;
      context__.validate_dims("data initialization","hyper_alpha","double",
          context__.to_vec(num_comps, 3));
      hyper_alpha = std::vector<std::vector<double>>(num_comps, std::vector<double>(3, std::numeric_limits<double>::quiet_NaN()));
      
      {
        std::vector<local_scalar_t__> hyper_alpha_flat__;
        current_statement__ = 97;
        assign(hyper_alpha_flat__, nil_index_list(),
          context__.vals_r("hyper_alpha"),
          "assigning variable hyper_alpha_flat__");
        current_statement__ = 97;
        pos__ = 1;
        current_statement__ = 97;
        for (int sym1__ = 1; sym1__ <= 3; ++sym1__) {
          current_statement__ = 97;
          for (int sym2__ = 1; sym2__ <= num_comps; ++sym2__) {
            current_statement__ = 97;
            assign(hyper_alpha,
              cons_list(index_uni(sym2__),
                cons_list(index_uni(sym1__), nil_index_list())),
              hyper_alpha_flat__[(pos__ - 1)],
              "assigning variable hyper_alpha");
            current_statement__ = 97;
            pos__ = (pos__ + 1);}}
      }
      current_statement__ = 98;
      validate_non_negative_index("hyper_ell", "num_ell", num_ell);
      current_statement__ = 99;
      context__.validate_dims("data initialization","hyper_ell","double",
          context__.to_vec(num_ell, 3));
      hyper_ell = std::vector<std::vector<double>>(num_ell, std::vector<double>(3, std::numeric_limits<double>::quiet_NaN()));
      
      {
        std::vector<local_scalar_t__> hyper_ell_flat__;
        current_statement__ = 99;
        assign(hyper_ell_flat__, nil_index_list(),
          context__.vals_r("hyper_ell"),
          "assigning variable hyper_ell_flat__");
        current_statement__ = 99;
        pos__ = 1;
        current_statement__ = 99;
        for (int sym1__ = 1; sym1__ <= 3; ++sym1__) {
          current_statement__ = 99;
          for (int sym2__ = 1; sym2__ <= num_ell; ++sym2__) {
            current_statement__ = 99;
            assign(hyper_ell,
              cons_list(index_uni(sym2__),
                cons_list(index_uni(sym1__), nil_index_list())),
              hyper_ell_flat__[(pos__ - 1)], "assigning variable hyper_ell");
            current_statement__ = 99;
            pos__ = (pos__ + 1);}}
      }
      current_statement__ = 100;
      validate_non_negative_index("hyper_wrp", "num_ns", num_ns);
      current_statement__ = 101;
      context__.validate_dims("data initialization","hyper_wrp","double",
          context__.to_vec(num_ns, 3));
      hyper_wrp = std::vector<std::vector<double>>(num_ns, std::vector<double>(3, std::numeric_limits<double>::quiet_NaN()));
      
      {
        std::vector<local_scalar_t__> hyper_wrp_flat__;
        current_statement__ = 101;
        assign(hyper_wrp_flat__, nil_index_list(),
          context__.vals_r("hyper_wrp"),
          "assigning variable hyper_wrp_flat__");
        current_statement__ = 101;
        pos__ = 1;
        current_statement__ = 101;
        for (int sym1__ = 1; sym1__ <= 3; ++sym1__) {
          current_statement__ = 101;
          for (int sym2__ = 1; sym2__ <= num_ns; ++sym2__) {
            current_statement__ = 101;
            assign(hyper_wrp,
              cons_list(index_uni(sym2__),
                cons_list(index_uni(sym1__), nil_index_list())),
              hyper_wrp_flat__[(pos__ - 1)], "assigning variable hyper_wrp");
            current_statement__ = 101;
            pos__ = (pos__ + 1);}}
      }
      current_statement__ = 102;
      validate_non_negative_index("hyper_teff", "num_uncrt > 0",
                                  logical_gt(num_uncrt, 0));
      current_statement__ = 103;
      context__.validate_dims("data initialization","hyper_teff","double",
          context__.to_vec(logical_gt(num_uncrt, 0), 3));
      hyper_teff = std::vector<std::vector<double>>(logical_gt(num_uncrt, 0), std::vector<double>(3, std::numeric_limits<double>::quiet_NaN()));
      
      {
        std::vector<local_scalar_t__> hyper_teff_flat__;
        current_statement__ = 103;
        assign(hyper_teff_flat__, nil_index_list(),
          context__.vals_r("hyper_teff"),
          "assigning variable hyper_teff_flat__");
        current_statement__ = 103;
        pos__ = 1;
        current_statement__ = 103;
        for (int sym1__ = 1; sym1__ <= 3; ++sym1__) {
          current_statement__ = 103;
          for (int sym2__ = 1; sym2__ <= logical_gt(num_uncrt, 0); ++sym2__) {
            current_statement__ = 103;
            assign(hyper_teff,
              cons_list(index_uni(sym2__),
                cons_list(index_uni(sym1__), nil_index_list())),
              hyper_teff_flat__[(pos__ - 1)], "assigning variable hyper_teff");
            current_statement__ = 103;
            pos__ = (pos__ + 1);}}
      }
      current_statement__ = 104;
      validate_non_negative_index("hyper_beta", "num_heter > 0",
                                  logical_gt(num_heter, 0));
      current_statement__ = 105;
      context__.validate_dims("data initialization","hyper_beta","double",
          context__.to_vec(logical_gt(num_heter, 0), 2));
      hyper_beta = std::vector<std::vector<double>>(logical_gt(num_heter, 0), std::vector<double>(2, std::numeric_limits<double>::quiet_NaN()));
      
      {
        std::vector<local_scalar_t__> hyper_beta_flat__;
        current_statement__ = 105;
        assign(hyper_beta_flat__, nil_index_list(),
          context__.vals_r("hyper_beta"),
          "assigning variable hyper_beta_flat__");
        current_statement__ = 105;
        pos__ = 1;
        current_statement__ = 105;
        for (int sym1__ = 1; sym1__ <= 2; ++sym1__) {
          current_statement__ = 105;
          for (int sym2__ = 1; sym2__ <= logical_gt(num_heter, 0); ++sym2__) {
            current_statement__ = 105;
            assign(hyper_beta,
              cons_list(index_uni(sym2__),
                cons_list(index_uni(sym1__), nil_index_list())),
              hyper_beta_flat__[(pos__ - 1)], "assigning variable hyper_beta");
            current_statement__ = 105;
            pos__ = (pos__ + 1);}}
      }
      current_statement__ = 106;
      validate_non_negative_index("y_norm", "num_obs", num_obs);
      current_statement__ = 107;
      context__.validate_dims("data initialization","y_norm","double",
          context__.to_vec(num_obs));
      y_norm = Eigen::Matrix<double, -1, 1>(num_obs);
      stan::math::fill(y_norm, std::numeric_limits<double>::quiet_NaN());
      
      {
        std::vector<local_scalar_t__> y_norm_flat__;
        current_statement__ = 107;
        assign(y_norm_flat__, nil_index_list(), context__.vals_r("y_norm"),
          "assigning variable y_norm_flat__");
        current_statement__ = 107;
        pos__ = 1;
        current_statement__ = 107;
        for (int sym1__ = 1; sym1__ <= num_obs; ++sym1__) {
          current_statement__ = 107;
          assign(y_norm, cons_list(index_uni(sym1__), nil_index_list()),
            y_norm_flat__[(pos__ - 1)], "assigning variable y_norm");
          current_statement__ = 107;
          pos__ = (pos__ + 1);}
      }
      current_statement__ = 108;
      context__.validate_dims("data initialization","prior_sigma","int",
          context__.to_vec(1, 2));
      prior_sigma = std::vector<std::vector<int>>(1, std::vector<int>(2, std::numeric_limits<int>::min()));
      
      {
        std::vector<int> prior_sigma_flat__;
        current_statement__ = 108;
        assign(prior_sigma_flat__, nil_index_list(),
          context__.vals_i("prior_sigma"),
          "assigning variable prior_sigma_flat__");
        current_statement__ = 108;
        pos__ = 1;
        current_statement__ = 108;
        for (int sym1__ = 1; sym1__ <= 2; ++sym1__) {
          current_statement__ = 108;
          for (int sym2__ = 1; sym2__ <= 1; ++sym2__) {
            current_statement__ = 108;
            assign(prior_sigma,
              cons_list(index_uni(sym2__),
                cons_list(index_uni(sym1__), nil_index_list())),
              prior_sigma_flat__[(pos__ - 1)],
              "assigning variable prior_sigma");
            current_statement__ = 108;
            pos__ = (pos__ + 1);}}
      }
      current_statement__ = 108;
      for (int sym1__ = 1; sym1__ <= 1; ++sym1__) {
        current_statement__ = 108;
        for (int sym2__ = 1; sym2__ <= 2; ++sym2__) {
          current_statement__ = 108;
          current_statement__ = 108;
          check_greater_or_equal(function__, "prior_sigma[sym1__, sym2__]",
                                 prior_sigma[(sym1__ - 1)][(sym2__ - 1)], 0);
        }}
      current_statement__ = 109;
      context__.validate_dims("data initialization","hyper_sigma","double",
          context__.to_vec(1, 3));
      hyper_sigma = std::vector<std::vector<double>>(1, std::vector<double>(3, std::numeric_limits<double>::quiet_NaN()));
      
      {
        std::vector<local_scalar_t__> hyper_sigma_flat__;
        current_statement__ = 109;
        assign(hyper_sigma_flat__, nil_index_list(),
          context__.vals_r("hyper_sigma"),
          "assigning variable hyper_sigma_flat__");
        current_statement__ = 109;
        pos__ = 1;
        current_statement__ = 109;
        for (int sym1__ = 1; sym1__ <= 3; ++sym1__) {
          current_statement__ = 109;
          for (int sym2__ = 1; sym2__ <= 1; ++sym2__) {
            current_statement__ = 109;
            assign(hyper_sigma,
              cons_list(index_uni(sym2__),
                cons_list(index_uni(sym1__), nil_index_list())),
              hyper_sigma_flat__[(pos__ - 1)],
              "assigning variable hyper_sigma");
            current_statement__ = 109;
            pos__ = (pos__ + 1);}}
      }
      current_statement__ = 110;
      validate_non_negative_index("m0", "num_obs", num_obs);
      current_statement__ = 111;
      m0 = Eigen::Matrix<double, -1, 1>(num_obs);
      stan::math::fill(m0, std::numeric_limits<double>::quiet_NaN());
      
      current_statement__ = 111;
      assign(m0, nil_index_list(), rep_vector(0.0, num_obs),
        "assigning variable m0");
      current_statement__ = 112;
      validate_non_negative_index("K_const", "num_comps", num_comps);
      current_statement__ = 113;
      validate_non_negative_index("K_const", "num_obs", num_obs);
      current_statement__ = 114;
      validate_non_negative_index("K_const", "num_obs", num_obs);
      current_statement__ = 115;
      K_const = std::vector<Eigen::Matrix<double, -1, -1>>(num_comps, Eigen::Matrix<double, -1, -1>(num_obs, num_obs));
      stan::math::fill(K_const, std::numeric_limits<double>::quiet_NaN());
      
      current_statement__ = 115;
      assign(K_const, nil_index_list(),
        STAN_kernel_const_all(num_obs, num_obs, x_cat, x_cat, x_cont_mask,
          x_cont_mask, x_cat_num_levels, components, pstream__),
        "assigning variable K_const");
      current_statement__ = 116;
      validate_non_negative_index("delta_vec", "num_obs", num_obs);
      current_statement__ = 117;
      delta_vec = Eigen::Matrix<double, -1, 1>(num_obs);
      stan::math::fill(delta_vec, std::numeric_limits<double>::quiet_NaN());
      
      current_statement__ = 117;
      assign(delta_vec, nil_index_list(), rep_vector(delta, num_obs),
        "assigning variable delta_vec");
      current_statement__ = 118;
      validate_non_negative_index("alpha", "num_comps", num_comps);
      current_statement__ = 119;
      validate_non_negative_index("ell", "num_ell", num_ell);
      current_statement__ = 120;
      validate_non_negative_index("wrp", "num_ns", num_ns);
      current_statement__ = 121;
      beta_1dim__ = std::numeric_limits<int>::min();
      
      current_statement__ = 121;
      beta_1dim__ = logical_gt(num_heter, 0);
      current_statement__ = 121;
      validate_non_negative_index("beta", "num_heter > 0", beta_1dim__);
      current_statement__ = 122;
      validate_non_negative_index("beta", "num_bt", num_bt);
      current_statement__ = 123;
      teff_raw_1dim__ = std::numeric_limits<int>::min();
      
      current_statement__ = 123;
      teff_raw_1dim__ = logical_gt(num_uncrt, 0);
      current_statement__ = 123;
      validate_non_negative_index("teff_raw", "num_uncrt > 0",
                                  teff_raw_1dim__);
      current_statement__ = 124;
      validate_non_negative_index("teff_raw", "num_bt", num_bt);
      current_statement__ = 125;
      validate_non_negative_index("sigma", "1", 1);
      current_statement__ = 126;
      teff_1dim__ = std::numeric_limits<int>::min();
      
      current_statement__ = 126;
      teff_1dim__ = logical_gt(num_uncrt, 0);
      current_statement__ = 126;
      validate_non_negative_index("teff", "num_uncrt > 0", teff_1dim__);
      current_statement__ = 127;
      validate_non_negative_index("teff", "num_bt", num_bt);
    } catch (const std::exception& e) {
      stan::lang::rethrow_located(e, locations_array__[current_statement__]);
      // Next line prevents compiler griping about no return
      throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***"); 
    }
    num_params_r__ = 0U;
    
    try {
      num_params_r__ += num_comps;
      num_params_r__ += num_ell;
      num_params_r__ += num_ns;
      num_params_r__ += beta_1dim__ * num_bt;
      num_params_r__ += teff_raw_1dim__ * num_bt;
      num_params_r__ += 1;
    } catch (const std::exception& e) {
      stan::lang::rethrow_located(e, locations_array__[current_statement__]);
      // Next line prevents compiler griping about no return
      throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***"); 
    }
  }
  template <bool propto__, bool jacobian__, typename VecR, typename VecI, stan::require_vector_like_t<VecR>* = nullptr, stan::require_vector_like_vt<std::is_integral, VecI>* = nullptr>
  inline stan::scalar_type_t<VecR> log_prob_impl(VecR& params_r__,
                                                 VecI& params_i__,
                                                 std::ostream* pstream__ = nullptr) const {
    using T__ = stan::scalar_type_t<VecR>;
    using local_scalar_t__ = T__;
    T__ lp__(0.0);
    stan::math::accumulator<T__> lp_accum__;
    static const char* function__ = "model_lgp_namespace::log_prob";
(void) function__;  // suppress unused var warning
    stan::io::reader<local_scalar_t__> in__(params_r__, params_i__);
    local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
    (void) DUMMY_VAR__;  // suppress unused var warning
    
    try {
      std::vector<local_scalar_t__> alpha;
      alpha = std::vector<local_scalar_t__>(num_comps, DUMMY_VAR__);
      
      current_statement__ = 1;
      for (int sym1__ = 1; sym1__ <= num_comps; ++sym1__) {
        current_statement__ = 1;
        assign(alpha, cons_list(index_uni(sym1__), nil_index_list()),
          in__.scalar(), "assigning variable alpha");}
      current_statement__ = 1;
      for (int sym1__ = 1; sym1__ <= num_comps; ++sym1__) {
        current_statement__ = 1;
        if (jacobian__) {
          current_statement__ = 1;
          assign(alpha, cons_list(index_uni(sym1__), nil_index_list()),
            stan::math::lb_constrain(alpha[(sym1__ - 1)], 1e-12, lp__),
            "assigning variable alpha");
        } else {
          current_statement__ = 1;
          assign(alpha, cons_list(index_uni(sym1__), nil_index_list()),
            stan::math::lb_constrain(alpha[(sym1__ - 1)], 1e-12),
            "assigning variable alpha");
        }}
      std::vector<local_scalar_t__> ell;
      ell = std::vector<local_scalar_t__>(num_ell, DUMMY_VAR__);
      
      current_statement__ = 2;
      for (int sym1__ = 1; sym1__ <= num_ell; ++sym1__) {
        current_statement__ = 2;
        assign(ell, cons_list(index_uni(sym1__), nil_index_list()),
          in__.scalar(), "assigning variable ell");}
      current_statement__ = 2;
      for (int sym1__ = 1; sym1__ <= num_ell; ++sym1__) {
        current_statement__ = 2;
        if (jacobian__) {
          current_statement__ = 2;
          assign(ell, cons_list(index_uni(sym1__), nil_index_list()),
            stan::math::lb_constrain(ell[(sym1__ - 1)], 1e-12, lp__),
            "assigning variable ell");
        } else {
          current_statement__ = 2;
          assign(ell, cons_list(index_uni(sym1__), nil_index_list()),
            stan::math::lb_constrain(ell[(sym1__ - 1)], 1e-12),
            "assigning variable ell");
        }}
      std::vector<local_scalar_t__> wrp;
      wrp = std::vector<local_scalar_t__>(num_ns, DUMMY_VAR__);
      
      current_statement__ = 3;
      for (int sym1__ = 1; sym1__ <= num_ns; ++sym1__) {
        current_statement__ = 3;
        assign(wrp, cons_list(index_uni(sym1__), nil_index_list()),
          in__.scalar(), "assigning variable wrp");}
      current_statement__ = 3;
      for (int sym1__ = 1; sym1__ <= num_ns; ++sym1__) {
        current_statement__ = 3;
        if (jacobian__) {
          current_statement__ = 3;
          assign(wrp, cons_list(index_uni(sym1__), nil_index_list()),
            stan::math::lb_constrain(wrp[(sym1__ - 1)], 1e-12, lp__),
            "assigning variable wrp");
        } else {
          current_statement__ = 3;
          assign(wrp, cons_list(index_uni(sym1__), nil_index_list()),
            stan::math::lb_constrain(wrp[(sym1__ - 1)], 1e-12),
            "assigning variable wrp");
        }}
      std::vector<Eigen::Matrix<local_scalar_t__, -1, 1>> beta;
      beta = std::vector<Eigen::Matrix<local_scalar_t__, -1, 1>>(beta_1dim__, Eigen::Matrix<local_scalar_t__, -1, 1>(num_bt));
      stan::math::fill(beta, DUMMY_VAR__);
      
      current_statement__ = 4;
      for (int sym1__ = 1; sym1__ <= beta_1dim__; ++sym1__) {
        current_statement__ = 4;
        assign(beta, cons_list(index_uni(sym1__), nil_index_list()),
          in__.vector(num_bt), "assigning variable beta");}
      current_statement__ = 4;
      for (int sym1__ = 1; sym1__ <= beta_1dim__; ++sym1__) {
        current_statement__ = 4;
        for (int sym2__ = 1; sym2__ <= num_bt; ++sym2__) {
          current_statement__ = 4;
          if (jacobian__) {
            current_statement__ = 4;
            assign(beta,
              cons_list(index_uni(sym1__),
                cons_list(index_uni(sym2__), nil_index_list())),
              stan::math::lub_constrain(beta[(sym1__ - 1)][(sym2__ - 1)],
                1e-12, (1 - 1e-12), lp__), "assigning variable beta");
          } else {
            current_statement__ = 4;
            assign(beta,
              cons_list(index_uni(sym1__),
                cons_list(index_uni(sym2__), nil_index_list())),
              stan::math::lub_constrain(beta[(sym1__ - 1)][(sym2__ - 1)],
                1e-12, (1 - 1e-12)), "assigning variable beta");
          }}}
      std::vector<Eigen::Matrix<local_scalar_t__, -1, 1>> teff_raw;
      teff_raw = std::vector<Eigen::Matrix<local_scalar_t__, -1, 1>>(teff_raw_1dim__, Eigen::Matrix<local_scalar_t__, -1, 1>(num_bt));
      stan::math::fill(teff_raw, DUMMY_VAR__);
      
      current_statement__ = 5;
      for (int sym1__ = 1; sym1__ <= teff_raw_1dim__; ++sym1__) {
        current_statement__ = 5;
        assign(teff_raw, cons_list(index_uni(sym1__), nil_index_list()),
          in__.vector(num_bt), "assigning variable teff_raw");}
      current_statement__ = 5;
      for (int sym1__ = 1; sym1__ <= teff_raw_1dim__; ++sym1__) {
        current_statement__ = 5;
        for (int sym2__ = 1; sym2__ <= num_bt; ++sym2__) {
          current_statement__ = 5;
          if (jacobian__) {
            current_statement__ = 5;
            assign(teff_raw,
              cons_list(index_uni(sym1__),
                cons_list(index_uni(sym2__), nil_index_list())),
              stan::math::lub_constrain(teff_raw[(sym1__ - 1)][(sym2__ - 1)],
                1e-12, (1 - 1e-12), lp__), "assigning variable teff_raw");
          } else {
            current_statement__ = 5;
            assign(teff_raw,
              cons_list(index_uni(sym1__),
                cons_list(index_uni(sym2__), nil_index_list())),
              stan::math::lub_constrain(teff_raw[(sym1__ - 1)][(sym2__ - 1)],
                1e-12, (1 - 1e-12)), "assigning variable teff_raw");
          }}}
      std::vector<local_scalar_t__> sigma;
      sigma = std::vector<local_scalar_t__>(1, DUMMY_VAR__);
      
      current_statement__ = 6;
      for (int sym1__ = 1; sym1__ <= 1; ++sym1__) {
        current_statement__ = 6;
        assign(sigma, cons_list(index_uni(sym1__), nil_index_list()),
          in__.scalar(), "assigning variable sigma");}
      current_statement__ = 6;
      for (int sym1__ = 1; sym1__ <= 1; ++sym1__) {
        current_statement__ = 6;
        if (jacobian__) {
          current_statement__ = 6;
          assign(sigma, cons_list(index_uni(sym1__), nil_index_list()),
            stan::math::lb_constrain(sigma[(sym1__ - 1)], 1e-12, lp__),
            "assigning variable sigma");
        } else {
          current_statement__ = 6;
          assign(sigma, cons_list(index_uni(sym1__), nil_index_list()),
            stan::math::lb_constrain(sigma[(sym1__ - 1)], 1e-12),
            "assigning variable sigma");
        }}
      std::vector<Eigen::Matrix<local_scalar_t__, -1, 1>> teff;
      teff = std::vector<Eigen::Matrix<local_scalar_t__, -1, 1>>(teff_1dim__, Eigen::Matrix<local_scalar_t__, -1, 1>(num_bt));
      stan::math::fill(teff, DUMMY_VAR__);
      
      current_statement__ = 10;
      for (int j = 1; j <= num_uncrt; ++j) {
        current_statement__ = 8;
        assign(teff, cons_list(index_uni(j), nil_index_list()),
          add(teff_lb[(j - 1)],
            elt_multiply(subtract(teff_ub[(j - 1)], teff_lb[(j - 1)]),
              teff_raw[(j - 1)])), "assigning variable teff");}
      {
        current_statement__ = 13;
        for (int j = 1; j <= num_comps; ++j) {
          current_statement__ = 11;
          lp_accum__.add(
            STAN_log_prior(alpha[(j - 1)], prior_alpha[(j - 1)],
              hyper_alpha[(j - 1)], pstream__));}
        current_statement__ = 16;
        for (int j = 1; j <= num_ell; ++j) {
          current_statement__ = 14;
          lp_accum__.add(
            STAN_log_prior(ell[(j - 1)], prior_ell[(j - 1)],
              hyper_ell[(j - 1)], pstream__));}
        current_statement__ = 19;
        for (int j = 1; j <= num_ns; ++j) {
          current_statement__ = 17;
          lp_accum__.add(
            STAN_log_prior(wrp[(j - 1)], prior_wrp[(j - 1)],
              hyper_wrp[(j - 1)], pstream__));}
        current_statement__ = 22;
        for (int j = 1; j <= num_heter; ++j) {
          current_statement__ = 20;
          lp_accum__.add(
            beta_lpdf<false>(beta[(j - 1)], hyper_beta[(j - 1)][(1 - 1)],
              hyper_beta[(j - 1)][(2 - 1)]));}
        current_statement__ = 32;
        for (int j = 1; j <= num_uncrt; ++j) {
          int ptype;
          ptype = std::numeric_limits<int>::min();
          
          current_statement__ = 23;
          ptype = prior_teff[(1 - 1)][(1 - 1)];
          int is_backwards;
          is_backwards = std::numeric_limits<int>::min();
          
          current_statement__ = 24;
          is_backwards = prior_teff[(1 - 1)][(2 - 1)];
          local_scalar_t__ direction;
          direction = DUMMY_VAR__;
          
          current_statement__ = 25;
          direction = pow(-1.0, is_backwards);
          current_statement__ = 26;
          validate_non_negative_index("tx", "num_bt", num_bt);
          Eigen::Matrix<local_scalar_t__, -1, 1> tx;
          tx = Eigen::Matrix<local_scalar_t__, -1, 1>(num_bt);
          stan::math::fill(tx, DUMMY_VAR__);
          
          current_statement__ = 27;
          assign(tx, nil_index_list(),
            multiply(direction, subtract(teff[(1 - 1)], teff_zero[(1 - 1)])),
            "assigning variable tx");
          current_statement__ = 30;
          for (int k = 1; k <= num_bt; ++k) {
            current_statement__ = 28;
            lp_accum__.add(
              STAN_log_prior(tx[(k - 1)], std::vector<int>{ptype, 0},
                hyper_teff[(1 - 1)], pstream__));}}
        current_statement__ = 33;
        lp_accum__.add(
          STAN_log_prior(sigma[(1 - 1)], prior_sigma[(1 - 1)],
            hyper_sigma[(1 - 1)], pstream__));
        current_statement__ = 47;
        if (logical_eq(is_likelihood_skipped, 0)) {
          current_statement__ = 34;
          validate_non_negative_index("Ky", "num_obs", num_obs);
          current_statement__ = 35;
          validate_non_negative_index("Ky", "num_obs", num_obs);
          Eigen::Matrix<local_scalar_t__, -1, -1> Ky;
          Ky = Eigen::Matrix<local_scalar_t__, -1, -1>(num_obs, num_obs);
          stan::math::fill(Ky, DUMMY_VAR__);
          
          current_statement__ = 36;
          assign(Ky, nil_index_list(), diag_matrix(delta_vec),
            "assigning variable Ky");
          current_statement__ = 37;
          validate_non_negative_index("KX", "num_comps", num_comps);
          current_statement__ = 38;
          validate_non_negative_index("KX", "num_obs", num_obs);
          current_statement__ = 39;
          validate_non_negative_index("KX", "num_obs", num_obs);
          std::vector<Eigen::Matrix<local_scalar_t__, -1, -1>> KX;
          KX = std::vector<Eigen::Matrix<local_scalar_t__, -1, -1>>(num_comps, Eigen::Matrix<local_scalar_t__, -1, -1>(num_obs, num_obs));
          stan::math::fill(KX, DUMMY_VAR__);
          
          current_statement__ = 40;
          assign(KX, nil_index_list(),
            STAN_kernel_all(num_obs, num_obs, K_const, components, x_cont,
              x_cont, x_cont_unnorm, x_cont_unnorm, alpha, ell, wrp, beta,
              teff, vm_params, idx_expand, idx_expand, teff_zero, pstream__),
            "assigning variable KX");
          current_statement__ = 43;
          for (int j = 1; j <= num_comps; ++j) {
            current_statement__ = 41;
            assign(Ky, nil_index_list(),
              add(stan::model::deep_copy(Ky), KX[(j - 1)]),
              "assigning variable Ky");}
          current_statement__ = 44;
          assign(Ky, nil_index_list(),
            add_diag(stan::model::deep_copy(Ky), square(sigma[(1 - 1)])),
            "assigning variable Ky");
          current_statement__ = 45;
          lp_accum__.add(
            multi_normal_cholesky_lpdf<propto__>(y_norm, m0,
              cholesky_decompose(Ky)));
        } 
      }
    } catch (const std::exception& e) {
      stan::lang::rethrow_located(e, locations_array__[current_statement__]);
      // Next line prevents compiler griping about no return
      throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***"); 
    }
    lp_accum__.add(lp__);
    return lp_accum__.sum();
    } // log_prob_impl() 
    
  template <typename RNG, typename VecR, typename VecI, typename VecVar, stan::require_vector_like_vt<std::is_floating_point, VecR>* = nullptr, stan::require_vector_like_vt<std::is_integral, VecI>* = nullptr, stan::require_std_vector_vt<std::is_floating_point, VecVar>* = nullptr>
  inline void write_array_impl(RNG& base_rng__, VecR& params_r__,
                               VecI& params_i__, VecVar& vars__,
                               const bool emit_transformed_parameters__ = true,
                               const bool emit_generated_quantities__ = true,
                               std::ostream* pstream__ = nullptr) const {
    using local_scalar_t__ = double;
    vars__.resize(0);
    stan::io::reader<local_scalar_t__> in__(params_r__, params_i__);
    static const char* function__ = "model_lgp_namespace::write_array";
(void) function__;  // suppress unused var warning
    (void) function__;  // suppress unused var warning
    double lp__ = 0.0;
    (void) lp__;  // dummy to suppress unused var warning
    stan::math::accumulator<double> lp_accum__;
    local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
    (void) DUMMY_VAR__;  // suppress unused var warning
    
    try {
      std::vector<double> alpha;
      alpha = std::vector<double>(num_comps, std::numeric_limits<double>::quiet_NaN());
      
      current_statement__ = 1;
      for (int sym1__ = 1; sym1__ <= num_comps; ++sym1__) {
        current_statement__ = 1;
        assign(alpha, cons_list(index_uni(sym1__), nil_index_list()),
          in__.scalar(), "assigning variable alpha");}
      current_statement__ = 1;
      for (int sym1__ = 1; sym1__ <= num_comps; ++sym1__) {
        current_statement__ = 1;
        assign(alpha, cons_list(index_uni(sym1__), nil_index_list()),
          stan::math::lb_constrain(alpha[(sym1__ - 1)], 1e-12),
          "assigning variable alpha");}
      std::vector<double> ell;
      ell = std::vector<double>(num_ell, std::numeric_limits<double>::quiet_NaN());
      
      current_statement__ = 2;
      for (int sym1__ = 1; sym1__ <= num_ell; ++sym1__) {
        current_statement__ = 2;
        assign(ell, cons_list(index_uni(sym1__), nil_index_list()),
          in__.scalar(), "assigning variable ell");}
      current_statement__ = 2;
      for (int sym1__ = 1; sym1__ <= num_ell; ++sym1__) {
        current_statement__ = 2;
        assign(ell, cons_list(index_uni(sym1__), nil_index_list()),
          stan::math::lb_constrain(ell[(sym1__ - 1)], 1e-12),
          "assigning variable ell");}
      std::vector<double> wrp;
      wrp = std::vector<double>(num_ns, std::numeric_limits<double>::quiet_NaN());
      
      current_statement__ = 3;
      for (int sym1__ = 1; sym1__ <= num_ns; ++sym1__) {
        current_statement__ = 3;
        assign(wrp, cons_list(index_uni(sym1__), nil_index_list()),
          in__.scalar(), "assigning variable wrp");}
      current_statement__ = 3;
      for (int sym1__ = 1; sym1__ <= num_ns; ++sym1__) {
        current_statement__ = 3;
        assign(wrp, cons_list(index_uni(sym1__), nil_index_list()),
          stan::math::lb_constrain(wrp[(sym1__ - 1)], 1e-12),
          "assigning variable wrp");}
      std::vector<Eigen::Matrix<double, -1, 1>> beta;
      beta = std::vector<Eigen::Matrix<double, -1, 1>>(beta_1dim__, Eigen::Matrix<double, -1, 1>(num_bt));
      stan::math::fill(beta, std::numeric_limits<double>::quiet_NaN());
      
      current_statement__ = 4;
      for (int sym1__ = 1; sym1__ <= beta_1dim__; ++sym1__) {
        current_statement__ = 4;
        assign(beta, cons_list(index_uni(sym1__), nil_index_list()),
          in__.vector(num_bt), "assigning variable beta");}
      current_statement__ = 4;
      for (int sym1__ = 1; sym1__ <= beta_1dim__; ++sym1__) {
        current_statement__ = 4;
        for (int sym2__ = 1; sym2__ <= num_bt; ++sym2__) {
          current_statement__ = 4;
          assign(beta,
            cons_list(index_uni(sym1__),
              cons_list(index_uni(sym2__), nil_index_list())),
            stan::math::lub_constrain(beta[(sym1__ - 1)][(sym2__ - 1)],
              1e-12, (1 - 1e-12)), "assigning variable beta");}}
      std::vector<Eigen::Matrix<double, -1, 1>> teff_raw;
      teff_raw = std::vector<Eigen::Matrix<double, -1, 1>>(teff_raw_1dim__, Eigen::Matrix<double, -1, 1>(num_bt));
      stan::math::fill(teff_raw, std::numeric_limits<double>::quiet_NaN());
      
      current_statement__ = 5;
      for (int sym1__ = 1; sym1__ <= teff_raw_1dim__; ++sym1__) {
        current_statement__ = 5;
        assign(teff_raw, cons_list(index_uni(sym1__), nil_index_list()),
          in__.vector(num_bt), "assigning variable teff_raw");}
      current_statement__ = 5;
      for (int sym1__ = 1; sym1__ <= teff_raw_1dim__; ++sym1__) {
        current_statement__ = 5;
        for (int sym2__ = 1; sym2__ <= num_bt; ++sym2__) {
          current_statement__ = 5;
          assign(teff_raw,
            cons_list(index_uni(sym1__),
              cons_list(index_uni(sym2__), nil_index_list())),
            stan::math::lub_constrain(teff_raw[(sym1__ - 1)][(sym2__ - 1)],
              1e-12, (1 - 1e-12)), "assigning variable teff_raw");}}
      std::vector<double> sigma;
      sigma = std::vector<double>(1, std::numeric_limits<double>::quiet_NaN());
      
      current_statement__ = 6;
      for (int sym1__ = 1; sym1__ <= 1; ++sym1__) {
        current_statement__ = 6;
        assign(sigma, cons_list(index_uni(sym1__), nil_index_list()),
          in__.scalar(), "assigning variable sigma");}
      current_statement__ = 6;
      for (int sym1__ = 1; sym1__ <= 1; ++sym1__) {
        current_statement__ = 6;
        assign(sigma, cons_list(index_uni(sym1__), nil_index_list()),
          stan::math::lb_constrain(sigma[(sym1__ - 1)], 1e-12),
          "assigning variable sigma");}
      std::vector<Eigen::Matrix<double, -1, 1>> teff;
      teff = std::vector<Eigen::Matrix<double, -1, 1>>(teff_1dim__, Eigen::Matrix<double, -1, 1>(num_bt));
      stan::math::fill(teff, std::numeric_limits<double>::quiet_NaN());
      
      for (int sym1__ = 1; sym1__ <= num_comps; ++sym1__) {
        vars__.emplace_back(alpha[(sym1__ - 1)]);}
      for (int sym1__ = 1; sym1__ <= num_ell; ++sym1__) {
        vars__.emplace_back(ell[(sym1__ - 1)]);}
      for (int sym1__ = 1; sym1__ <= num_ns; ++sym1__) {
        vars__.emplace_back(wrp[(sym1__ - 1)]);}
      for (int sym1__ = 1; sym1__ <= num_bt; ++sym1__) {
        for (int sym2__ = 1; sym2__ <= beta_1dim__; ++sym2__) {
          vars__.emplace_back(beta[(sym2__ - 1)][(sym1__ - 1)]);}}
      for (int sym1__ = 1; sym1__ <= num_bt; ++sym1__) {
        for (int sym2__ = 1; sym2__ <= teff_raw_1dim__; ++sym2__) {
          vars__.emplace_back(teff_raw[(sym2__ - 1)][(sym1__ - 1)]);}}
      for (int sym1__ = 1; sym1__ <= 1; ++sym1__) {
        vars__.emplace_back(sigma[(sym1__ - 1)]);}
      if (logical_negation((primitive_value(emit_transformed_parameters__) ||
            primitive_value(emit_generated_quantities__)))) {
        return ;
      } 
      current_statement__ = 10;
      for (int j = 1; j <= num_uncrt; ++j) {
        current_statement__ = 8;
        assign(teff, cons_list(index_uni(j), nil_index_list()),
          add(teff_lb[(j - 1)],
            elt_multiply(subtract(teff_ub[(j - 1)], teff_lb[(j - 1)]),
              teff_raw[(j - 1)])), "assigning variable teff");}
      if (emit_transformed_parameters__) {
        for (int sym1__ = 1; sym1__ <= num_bt; ++sym1__) {
          for (int sym2__ = 1; sym2__ <= teff_1dim__; ++sym2__) {
            vars__.emplace_back(teff[(sym2__ - 1)][(sym1__ - 1)]);}}
      } 
      if (logical_negation(emit_generated_quantities__)) {
        return ;
      } 
    } catch (const std::exception& e) {
      stan::lang::rethrow_located(e, locations_array__[current_statement__]);
      // Next line prevents compiler griping about no return
      throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***"); 
    }
    } // write_array_impl() 
    
  template <typename VecVar, typename VecI, stan::require_std_vector_t<VecVar>* = nullptr, stan::require_vector_like_vt<std::is_integral, VecI>* = nullptr>
  inline void transform_inits_impl(const stan::io::var_context& context__,
                                   VecI& params_i__, VecVar& vars__,
                                   std::ostream* pstream__ = nullptr) const {
    using local_scalar_t__ = double;
    vars__.clear();
    vars__.reserve(num_params_r__);
    
    try {
      int pos__;
      pos__ = std::numeric_limits<int>::min();
      
      pos__ = 1;
      std::vector<double> alpha;
      alpha = std::vector<double>(num_comps, std::numeric_limits<double>::quiet_NaN());
      
      current_statement__ = 1;
      assign(alpha, nil_index_list(), context__.vals_r("alpha"),
        "assigning variable alpha");
      std::vector<double> alpha_free__;
      alpha_free__ = std::vector<double>(num_comps, std::numeric_limits<double>::quiet_NaN());
      
      current_statement__ = 1;
      for (int sym1__ = 1; sym1__ <= num_comps; ++sym1__) {
        current_statement__ = 1;
        assign(alpha_free__, cons_list(index_uni(sym1__), nil_index_list()),
          stan::math::lb_free(alpha[(sym1__ - 1)], 1e-12),
          "assigning variable alpha_free__");}
      std::vector<double> ell;
      ell = std::vector<double>(num_ell, std::numeric_limits<double>::quiet_NaN());
      
      current_statement__ = 2;
      assign(ell, nil_index_list(), context__.vals_r("ell"),
        "assigning variable ell");
      std::vector<double> ell_free__;
      ell_free__ = std::vector<double>(num_ell, std::numeric_limits<double>::quiet_NaN());
      
      current_statement__ = 2;
      for (int sym1__ = 1; sym1__ <= num_ell; ++sym1__) {
        current_statement__ = 2;
        assign(ell_free__, cons_list(index_uni(sym1__), nil_index_list()),
          stan::math::lb_free(ell[(sym1__ - 1)], 1e-12),
          "assigning variable ell_free__");}
      std::vector<double> wrp;
      wrp = std::vector<double>(num_ns, std::numeric_limits<double>::quiet_NaN());
      
      current_statement__ = 3;
      assign(wrp, nil_index_list(), context__.vals_r("wrp"),
        "assigning variable wrp");
      std::vector<double> wrp_free__;
      wrp_free__ = std::vector<double>(num_ns, std::numeric_limits<double>::quiet_NaN());
      
      current_statement__ = 3;
      for (int sym1__ = 1; sym1__ <= num_ns; ++sym1__) {
        current_statement__ = 3;
        assign(wrp_free__, cons_list(index_uni(sym1__), nil_index_list()),
          stan::math::lb_free(wrp[(sym1__ - 1)], 1e-12),
          "assigning variable wrp_free__");}
      std::vector<Eigen::Matrix<double, -1, 1>> beta;
      beta = std::vector<Eigen::Matrix<double, -1, 1>>(beta_1dim__, Eigen::Matrix<double, -1, 1>(num_bt));
      stan::math::fill(beta, std::numeric_limits<double>::quiet_NaN());
      
      {
        std::vector<local_scalar_t__> beta_flat__;
        current_statement__ = 4;
        assign(beta_flat__, nil_index_list(), context__.vals_r("beta"),
          "assigning variable beta_flat__");
        current_statement__ = 4;
        pos__ = 1;
        current_statement__ = 4;
        for (int sym1__ = 1; sym1__ <= num_bt; ++sym1__) {
          current_statement__ = 4;
          for (int sym2__ = 1; sym2__ <= beta_1dim__; ++sym2__) {
            current_statement__ = 4;
            assign(beta,
              cons_list(index_uni(sym2__),
                cons_list(index_uni(sym1__), nil_index_list())),
              beta_flat__[(pos__ - 1)], "assigning variable beta");
            current_statement__ = 4;
            pos__ = (pos__ + 1);}}
      }
      std::vector<Eigen::Matrix<double, -1, 1>> beta_free__;
      beta_free__ = std::vector<Eigen::Matrix<double, -1, 1>>(beta_1dim__, Eigen::Matrix<double, -1, 1>(num_bt));
      stan::math::fill(beta_free__, std::numeric_limits<double>::quiet_NaN());
      
      current_statement__ = 4;
      for (int sym1__ = 1; sym1__ <= beta_1dim__; ++sym1__) {
        current_statement__ = 4;
        for (int sym2__ = 1; sym2__ <= num_bt; ++sym2__) {
          current_statement__ = 4;
          assign(beta_free__,
            cons_list(index_uni(sym1__),
              cons_list(index_uni(sym2__), nil_index_list())),
            stan::math::lub_free(beta[(sym1__ - 1)][(sym2__ - 1)], 1e-12,
              (1 - 1e-12)), "assigning variable beta_free__");}}
      std::vector<Eigen::Matrix<double, -1, 1>> teff_raw;
      teff_raw = std::vector<Eigen::Matrix<double, -1, 1>>(teff_raw_1dim__, Eigen::Matrix<double, -1, 1>(num_bt));
      stan::math::fill(teff_raw, std::numeric_limits<double>::quiet_NaN());
      
      {
        std::vector<local_scalar_t__> teff_raw_flat__;
        current_statement__ = 5;
        assign(teff_raw_flat__, nil_index_list(),
          context__.vals_r("teff_raw"), "assigning variable teff_raw_flat__");
        current_statement__ = 5;
        pos__ = 1;
        current_statement__ = 5;
        for (int sym1__ = 1; sym1__ <= num_bt; ++sym1__) {
          current_statement__ = 5;
          for (int sym2__ = 1; sym2__ <= teff_raw_1dim__; ++sym2__) {
            current_statement__ = 5;
            assign(teff_raw,
              cons_list(index_uni(sym2__),
                cons_list(index_uni(sym1__), nil_index_list())),
              teff_raw_flat__[(pos__ - 1)], "assigning variable teff_raw");
            current_statement__ = 5;
            pos__ = (pos__ + 1);}}
      }
      std::vector<Eigen::Matrix<double, -1, 1>> teff_raw_free__;
      teff_raw_free__ = std::vector<Eigen::Matrix<double, -1, 1>>(teff_raw_1dim__, Eigen::Matrix<double, -1, 1>(num_bt));
      stan::math::fill(teff_raw_free__, std::numeric_limits<double>::quiet_NaN());
      
      current_statement__ = 5;
      for (int sym1__ = 1; sym1__ <= teff_raw_1dim__; ++sym1__) {
        current_statement__ = 5;
        for (int sym2__ = 1; sym2__ <= num_bt; ++sym2__) {
          current_statement__ = 5;
          assign(teff_raw_free__,
            cons_list(index_uni(sym1__),
              cons_list(index_uni(sym2__), nil_index_list())),
            stan::math::lub_free(teff_raw[(sym1__ - 1)][(sym2__ - 1)], 1e-12,
              (1 - 1e-12)), "assigning variable teff_raw_free__");}}
      std::vector<double> sigma;
      sigma = std::vector<double>(1, std::numeric_limits<double>::quiet_NaN());
      
      current_statement__ = 6;
      assign(sigma, nil_index_list(), context__.vals_r("sigma"),
        "assigning variable sigma");
      std::vector<double> sigma_free__;
      sigma_free__ = std::vector<double>(1, std::numeric_limits<double>::quiet_NaN());
      
      current_statement__ = 6;
      for (int sym1__ = 1; sym1__ <= 1; ++sym1__) {
        current_statement__ = 6;
        assign(sigma_free__, cons_list(index_uni(sym1__), nil_index_list()),
          stan::math::lb_free(sigma[(sym1__ - 1)], 1e-12),
          "assigning variable sigma_free__");}
      for (int sym1__ = 1; sym1__ <= num_comps; ++sym1__) {
        vars__.emplace_back(alpha_free__[(sym1__ - 1)]);}
      for (int sym1__ = 1; sym1__ <= num_ell; ++sym1__) {
        vars__.emplace_back(ell_free__[(sym1__ - 1)]);}
      for (int sym1__ = 1; sym1__ <= num_ns; ++sym1__) {
        vars__.emplace_back(wrp_free__[(sym1__ - 1)]);}
      for (int sym1__ = 1; sym1__ <= beta_1dim__; ++sym1__) {
        for (int sym2__ = 1; sym2__ <= num_bt; ++sym2__) {
          vars__.emplace_back(beta_free__[(sym1__ - 1)][(sym2__ - 1)]);}}
      for (int sym1__ = 1; sym1__ <= teff_raw_1dim__; ++sym1__) {
        for (int sym2__ = 1; sym2__ <= num_bt; ++sym2__) {
          vars__.emplace_back(teff_raw_free__[(sym1__ - 1)][(sym2__ - 1)]);}}
      for (int sym1__ = 1; sym1__ <= 1; ++sym1__) {
        vars__.emplace_back(sigma_free__[(sym1__ - 1)]);}
    } catch (const std::exception& e) {
      stan::lang::rethrow_located(e, locations_array__[current_statement__]);
      // Next line prevents compiler griping about no return
      throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***"); 
    }
    } // transform_inits_impl() 
    
  inline void get_param_names(std::vector<std::string>& names__) const {
    
    names__.clear();
    names__.emplace_back("alpha");
    names__.emplace_back("ell");
    names__.emplace_back("wrp");
    names__.emplace_back("beta");
    names__.emplace_back("teff_raw");
    names__.emplace_back("sigma");
    names__.emplace_back("teff");
    } // get_param_names() 
    
  inline void get_dims(std::vector<std::vector<size_t>>& dimss__) const {
    dimss__.clear();
    dimss__.emplace_back(std::vector<size_t>{static_cast<size_t>(num_comps)});
    
    dimss__.emplace_back(std::vector<size_t>{static_cast<size_t>(num_ell)});
    
    dimss__.emplace_back(std::vector<size_t>{static_cast<size_t>(num_ns)});
    
    dimss__.emplace_back(std::vector<size_t>{static_cast<size_t>(beta_1dim__)
                                             , static_cast<size_t>(num_bt)});
    
    dimss__.emplace_back(std::vector<size_t>{
                                             static_cast<size_t>(teff_raw_1dim__)
                                             , static_cast<size_t>(num_bt)});
    
    dimss__.emplace_back(std::vector<size_t>{static_cast<size_t>(1)});
    
    dimss__.emplace_back(std::vector<size_t>{static_cast<size_t>(teff_1dim__)
                                             , static_cast<size_t>(num_bt)});
    
    } // get_dims() 
    
  inline void constrained_param_names(
                                      std::vector<std::string>& param_names__,
                                      bool emit_transformed_parameters__ = true,
                                      bool emit_generated_quantities__ = true) const
    final {
    
    for (int sym1__ = 1; sym1__ <= num_comps; ++sym1__) {
      {
        param_names__.emplace_back(std::string() + "alpha" + '.' + std::to_string(sym1__));
      }}
    for (int sym1__ = 1; sym1__ <= num_ell; ++sym1__) {
      {
        param_names__.emplace_back(std::string() + "ell" + '.' + std::to_string(sym1__));
      }}
    for (int sym1__ = 1; sym1__ <= num_ns; ++sym1__) {
      {
        param_names__.emplace_back(std::string() + "wrp" + '.' + std::to_string(sym1__));
      }}
    for (int sym1__ = 1; sym1__ <= num_bt; ++sym1__) {
      {
        for (int sym2__ = 1; sym2__ <= beta_1dim__; ++sym2__) {
          {
            param_names__.emplace_back(std::string() + "beta" + '.' + std::to_string(sym2__) + '.' + std::to_string(sym1__));
          }}
      }}
    for (int sym1__ = 1; sym1__ <= num_bt; ++sym1__) {
      {
        for (int sym2__ = 1; sym2__ <= teff_raw_1dim__; ++sym2__) {
          {
            param_names__.emplace_back(std::string() + "teff_raw" + '.' + std::to_string(sym2__) + '.' + std::to_string(sym1__));
          }}
      }}
    for (int sym1__ = 1; sym1__ <= 1; ++sym1__) {
      {
        param_names__.emplace_back(std::string() + "sigma" + '.' + std::to_string(sym1__));
      }}
    if (emit_transformed_parameters__) {
      for (int sym1__ = 1; sym1__ <= num_bt; ++sym1__) {
        {
          for (int sym2__ = 1; sym2__ <= teff_1dim__; ++sym2__) {
            {
              param_names__.emplace_back(std::string() + "teff" + '.' + std::to_string(sym2__) + '.' + std::to_string(sym1__));
            }}
        }}
    }
    
    if (emit_generated_quantities__) {
      
    }
    
    } // constrained_param_names() 
    
  inline void unconstrained_param_names(
                                        std::vector<std::string>& param_names__,
                                        bool emit_transformed_parameters__ = true,
                                        bool emit_generated_quantities__ = true) const
    final {
    
    for (int sym1__ = 1; sym1__ <= num_comps; ++sym1__) {
      {
        param_names__.emplace_back(std::string() + "alpha" + '.' + std::to_string(sym1__));
      }}
    for (int sym1__ = 1; sym1__ <= num_ell; ++sym1__) {
      {
        param_names__.emplace_back(std::string() + "ell" + '.' + std::to_string(sym1__));
      }}
    for (int sym1__ = 1; sym1__ <= num_ns; ++sym1__) {
      {
        param_names__.emplace_back(std::string() + "wrp" + '.' + std::to_string(sym1__));
      }}
    for (int sym1__ = 1; sym1__ <= num_bt; ++sym1__) {
      {
        for (int sym2__ = 1; sym2__ <= beta_1dim__; ++sym2__) {
          {
            param_names__.emplace_back(std::string() + "beta" + '.' + std::to_string(sym2__) + '.' + std::to_string(sym1__));
          }}
      }}
    for (int sym1__ = 1; sym1__ <= num_bt; ++sym1__) {
      {
        for (int sym2__ = 1; sym2__ <= teff_raw_1dim__; ++sym2__) {
          {
            param_names__.emplace_back(std::string() + "teff_raw" + '.' + std::to_string(sym2__) + '.' + std::to_string(sym1__));
          }}
      }}
    for (int sym1__ = 1; sym1__ <= 1; ++sym1__) {
      {
        param_names__.emplace_back(std::string() + "sigma" + '.' + std::to_string(sym1__));
      }}
    if (emit_transformed_parameters__) {
      for (int sym1__ = 1; sym1__ <= num_bt; ++sym1__) {
        {
          for (int sym2__ = 1; sym2__ <= teff_1dim__; ++sym2__) {
            {
              param_names__.emplace_back(std::string() + "teff" + '.' + std::to_string(sym2__) + '.' + std::to_string(sym1__));
            }}
        }}
    }
    
    if (emit_generated_quantities__) {
      
    }
    
    } // unconstrained_param_names() 
    
  inline std::string get_constrained_sizedtypes() const {
    stringstream s__;
    s__ << "[{\"name\":\"alpha\",\"type\":{\"name\":\"array\",\"length\":" << num_comps << ",\"element_type\":{\"name\":\"real\"}},\"block\":\"parameters\"},{\"name\":\"ell\",\"type\":{\"name\":\"array\",\"length\":" << num_ell << ",\"element_type\":{\"name\":\"real\"}},\"block\":\"parameters\"},{\"name\":\"wrp\",\"type\":{\"name\":\"array\",\"length\":" << num_ns << ",\"element_type\":{\"name\":\"real\"}},\"block\":\"parameters\"},{\"name\":\"beta\",\"type\":{\"name\":\"array\",\"length\":" << beta_1dim__ << ",\"element_type\":{\"name\":\"vector\",\"length\":" << num_bt << "}},\"block\":\"parameters\"},{\"name\":\"teff_raw\",\"type\":{\"name\":\"array\",\"length\":" << teff_raw_1dim__ << ",\"element_type\":{\"name\":\"vector\",\"length\":" << num_bt << "}},\"block\":\"parameters\"},{\"name\":\"sigma\",\"type\":{\"name\":\"array\",\"length\":" << 1 << ",\"element_type\":{\"name\":\"real\"}},\"block\":\"parameters\"},{\"name\":\"teff\",\"type\":{\"name\":\"array\",\"length\":" << teff_1dim__ << ",\"element_type\":{\"name\":\"vector\",\"length\":" << num_bt << "}},\"block\":\"transformed_parameters\"}]";
    return s__.str();
    } // get_constrained_sizedtypes() 
    
  inline std::string get_unconstrained_sizedtypes() const {
    stringstream s__;
    s__ << "[{\"name\":\"alpha\",\"type\":{\"name\":\"array\",\"length\":" << num_comps << ",\"element_type\":{\"name\":\"real\"}},\"block\":\"parameters\"},{\"name\":\"ell\",\"type\":{\"name\":\"array\",\"length\":" << num_ell << ",\"element_type\":{\"name\":\"real\"}},\"block\":\"parameters\"},{\"name\":\"wrp\",\"type\":{\"name\":\"array\",\"length\":" << num_ns << ",\"element_type\":{\"name\":\"real\"}},\"block\":\"parameters\"},{\"name\":\"beta\",\"type\":{\"name\":\"array\",\"length\":" << beta_1dim__ << ",\"element_type\":{\"name\":\"vector\",\"length\":" << num_bt << "}},\"block\":\"parameters\"},{\"name\":\"teff_raw\",\"type\":{\"name\":\"array\",\"length\":" << teff_raw_1dim__ << ",\"element_type\":{\"name\":\"vector\",\"length\":" << num_bt << "}},\"block\":\"parameters\"},{\"name\":\"sigma\",\"type\":{\"name\":\"array\",\"length\":" << 1 << ",\"element_type\":{\"name\":\"real\"}},\"block\":\"parameters\"},{\"name\":\"teff\",\"type\":{\"name\":\"array\",\"length\":" << teff_1dim__ << ",\"element_type\":{\"name\":\"vector\",\"length\":" << num_bt << "}},\"block\":\"transformed_parameters\"}]";
    return s__.str();
    } // get_unconstrained_sizedtypes() 
    
  
    // Begin method overload boilerplate
    template <typename RNG>
    inline void write_array(RNG& base_rng,
                            Eigen::Matrix<double,Eigen::Dynamic,1>& params_r,
                            Eigen::Matrix<double,Eigen::Dynamic,1>& vars,
                            const bool emit_transformed_parameters = true,
                            const bool emit_generated_quantities = true,
                            std::ostream* pstream = nullptr) const {
      std::vector<double> vars_vec(vars.size());
      std::vector<int> params_i;
      write_array_impl(base_rng, params_r, params_i, vars_vec,
          emit_transformed_parameters, emit_generated_quantities, pstream);
      vars.resize(vars_vec.size());
      for (int i = 0; i < vars.size(); ++i) {
        vars.coeffRef(i) = vars_vec[i];
      }
    }
    template <typename RNG>
    inline void write_array(RNG& base_rng, std::vector<double>& params_r,
                            std::vector<int>& params_i,
                            std::vector<double>& vars,
                            bool emit_transformed_parameters = true,
                            bool emit_generated_quantities = true,
                            std::ostream* pstream = nullptr) const {
      write_array_impl(base_rng, params_r, params_i, vars, emit_transformed_parameters, emit_generated_quantities, pstream);
    }
    template <bool propto__, bool jacobian__, typename T_>
    inline T_ log_prob(Eigen::Matrix<T_,Eigen::Dynamic,1>& params_r,
                       std::ostream* pstream = nullptr) const {
      Eigen::Matrix<int, -1, 1> params_i;
      return log_prob_impl<propto__, jacobian__>(params_r, params_i, pstream);
    }
    template <bool propto__, bool jacobian__, typename T__>
    inline T__ log_prob(std::vector<T__>& params_r,
                        std::vector<int>& params_i,
                        std::ostream* pstream = nullptr) const {
      return log_prob_impl<propto__, jacobian__>(params_r, params_i, pstream);
    }
  
    inline void transform_inits(const stan::io::var_context& context,
                         Eigen::Matrix<double, Eigen::Dynamic, 1>& params_r,
                         std::ostream* pstream = nullptr) const final {
      std::vector<double> params_r_vec(params_r.size());
      std::vector<int> params_i;
      transform_inits_impl(context, params_i, params_r_vec, pstream);
      params_r.resize(params_r_vec.size());
      for (int i = 0; i < params_r.size(); ++i) {
        params_r.coeffRef(i) = params_r_vec[i];
      }
    }
    inline void transform_inits(const stan::io::var_context& context,
                                std::vector<int>& params_i,
                                std::vector<double>& vars,
                                std::ostream* pstream = nullptr) const final {
      transform_inits_impl(context, params_i, vars, pstream);
    }        
};
}
using stan_model = model_lgp_namespace::model_lgp;
#ifndef USING_R
// Boilerplate
stan::model::model_base& new_model(
        stan::io::var_context& data_context,
        unsigned int seed,
        std::ostream* msg_stream) {
  stan_model* m = new stan_model(data_context, seed, msg_stream);
  return *m;
}
stan::math::profile_map& get_stan_profile_data() {
  return model_lgp_namespace::profiles__;
}
#endif
#endif
